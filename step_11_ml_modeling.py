# step_11_ml_modeling.py - ML/AI ëª¨ë¸ë§ í†µí•© ëª¨ë“ˆ

"""
Step 11 ML Modeling & AI í†µí•© ëª¨ë“ˆ

ML/NN/AI ëª¨ë¸ë§ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ëª¨ë“ˆ
- ë¶„ë¥˜, íšŒê·€, í´ëŸ¬ìŠ¤í„°ë§
- ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- ê²°ê³¼ ì‹œê°í™”
"""

import dearpygui.dearpygui as dpg
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
import traceback
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# --- DPG Tags ---
TAG_S11_GROUP = "step11_ml_modeling_group"
TAG_S11_UPPER_VIZ_WINDOW = "step11_upper_viz_window"
TAG_S11_LOWER_CONTROL_PANEL = "step11_lower_control_panel"
TAG_S11_VIZ_TAB_BAR = "step11_viz_tab_bar"
TAG_S11_DF_SELECTOR = "step11_df_selector"
TAG_S11_MODEL_TYPE_SELECTOR = "step11_model_type_selector"
TAG_S11_ALGORITHM_SELECTOR = "step11_algorithm_selector"
TAG_S11_FEATURE_LIST = "step11_feature_list"
TAG_S11_TARGET_COMBO = "step11_target_combo"
TAG_S11_TRAIN_BUTTON = "step11_train_button"
TAG_S11_DYNAMIC_PARAMS_AREA = "step11_dynamic_params_area"

# --- Module State ---
_module_main_callbacks: Optional[Dict] = None
_util_funcs: Optional[Dict[str, Any]] = None
_available_dfs: Dict[str, pd.DataFrame] = {}
_selected_df_name: str = ""
_selected_features: List[str] = []
_trained_models: Dict[str, Any] = {}
_model_counter: int = 0

# --- ML ì•Œê³ ë¦¬ì¦˜ ì •ì˜ ---
ML_ALGORITHMS = {
    "Classification": {
        "Logistic Regression": {"module": "sklearn.linear_model", "class": "LogisticRegression"},
        "Random Forest": {"module": "sklearn.ensemble", "class": "RandomForestClassifier"},
        "SVM": {"module": "sklearn.svm", "class": "SVC"},
        "KNN": {"module": "sklearn.neighbors", "class": "KNeighborsClassifier"},
        "Decision Tree": {"module": "sklearn.tree", "class": "DecisionTreeClassifier"},
        "Gradient Boosting": {"module": "sklearn.ensemble", "class": "GradientBoostingClassifier"},
        "Neural Network": {"module": "sklearn.neural_network", "class": "MLPClassifier"}
    },
    "Regression": {
        "Linear Regression": {"module": "sklearn.linear_model", "class": "LinearRegression"},
        "Random Forest": {"module": "sklearn.ensemble", "class": "RandomForestRegressor"},
        "SVR": {"module": "sklearn.svm", "class": "SVR"},
        "KNN": {"module": "sklearn.neighbors", "class": "KNeighborsRegressor"},
        "Decision Tree": {"module": "sklearn.tree", "class": "DecisionTreeRegressor"},
        "Gradient Boosting": {"module": "sklearn.ensemble", "class": "GradientBoostingRegressor"},
        "Neural Network": {"module": "sklearn.neural_network", "class": "MLPRegressor"}
    },
    "Clustering": {
        "K-Means": {"module": "sklearn.cluster", "class": "KMeans"},
        "DBSCAN": {"module": "sklearn.cluster", "class": "DBSCAN"},
        "Hierarchical": {"module": "sklearn.cluster", "class": "AgglomerativeClustering"},
        "Gaussian Mixture": {"module": "sklearn.mixture", "class": "GaussianMixture"}
    }
}

# --- í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ì˜ ---
HYPERPARAMETERS = {
    "LogisticRegression": {
        "C": {"type": "float", "default": 1.0, "min": 0.01, "max": 100.0},
        "max_iter": {"type": "int", "default": 100, "min": 50, "max": 1000}
    },
    "RandomForestClassifier": {
        "n_estimators": {"type": "int", "default": 100, "min": 10, "max": 500},
        "max_depth": {"type": "int", "default": 10, "min": 1, "max": 50},
        "min_samples_split": {"type": "int", "default": 2, "min": 2, "max": 20}
    },
    "RandomForestRegressor": {
        "n_estimators": {"type": "int", "default": 100, "min": 10, "max": 500},
        "max_depth": {"type": "int", "default": 10, "min": 1, "max": 50},
        "min_samples_split": {"type": "int", "default": 2, "min": 2, "max": 20}
    },
    "SVC": {
        "C": {"type": "float", "default": 1.0, "min": 0.01, "max": 100.0},
        "kernel": {"type": "combo", "default": "rbf", "options": ["linear", "poly", "rbf", "sigmoid"]}
    },
    "KMeans": {
        "n_clusters": {"type": "int", "default": 3, "min": 2, "max": 20},
        "n_init": {"type": "int", "default": 10, "min": 1, "max": 50}
    },
    "MLPClassifier": {
        "hidden_layer_sizes": {"type": "text", "default": "100,50", "hint": "e.g., 100,50"},
        "activation": {"type": "combo", "default": "relu", "options": ["relu", "tanh", "logistic"]},
        "learning_rate_init": {"type": "float", "default": 0.001, "min": 0.0001, "max": 0.1},
        "max_iter": {"type": "int", "default": 200, "min": 50, "max": 1000}
    }
}

def create_ui(step_name: str, parent_container_tag: str, main_callbacks: dict):
    """Step 11 UI ìƒì„±"""
    global _module_main_callbacks, _util_funcs
    _module_main_callbacks = main_callbacks
    _util_funcs = main_callbacks.get('get_util_funcs', lambda: {})()
    
    main_callbacks['register_step_group_tag'](step_name, TAG_S11_GROUP)

    with dpg.group(tag=TAG_S11_GROUP, parent=parent_container_tag, show=False):
        dpg.add_text(f"--- {step_name} ---")
        dpg.add_separator()
        
        # ì „ì²´ ë†’ì´ ì„¤ì •
        total_height = 1000
        upper_height = int(total_height * 0.6)
        lower_height = int(total_height * 0.4)
        
        # ìƒë¶€ ì‹œê°í™” ì˜ì—­
        with dpg.child_window(height=upper_height, border=True, tag=TAG_S11_UPPER_VIZ_WINDOW):
            dpg.add_text("Model Results", color=(255, 255, 0))
            dpg.add_separator()
            
            with dpg.tab_bar(tag=TAG_S11_VIZ_TAB_BAR):
                with dpg.tab(label="Guide"):
                    _create_guide_tab()
        
        # í•˜ë¶€ ì»¨íŠ¸ë¡¤ íŒ¨ë„
        with dpg.child_window(height=lower_height, border=True, tag=TAG_S11_LOWER_CONTROL_PANEL):
            with dpg.group(horizontal=True):
                # ì¢Œì¸¡: ë°ì´í„°/ëª¨ë¸ ì„ íƒ
                _create_left_panel()
                
                # ì¤‘ì•™: ë³€ìˆ˜ ì„ íƒ
                _create_center_panel()
                
                # ìš°ì¸¡: ì˜µì…˜ ì„¤ì •
                _create_right_panel()

    main_callbacks['register_module_updater'](step_name, update_ui)   
    # 2. UIê°€ ì²˜ìŒ ìƒì„±ë  ë•Œ DataFrame ëª©ë¡ì„ í•œë²ˆ ë¡œë“œí•©ë‹ˆë‹¤.
    update_ui()

def _create_guide_tab():
    """ê°€ì´ë“œ íƒ­ ìƒì„±"""
    dpg.add_text("ML/AI Modeling Guide", color=(255, 255, 0))
    dpg.add_separator()
    dpg.add_text("1. Select DataFrame and Model Type")
    dpg.add_text("2. Choose Algorithm")
    dpg.add_text("3. Select Features (and Target for supervised learning)")
    dpg.add_text("4. Configure Hyperparameters")
    dpg.add_text("5. Train Model")
    dpg.add_separator()
    dpg.add_text("Available Model Types:")
    dpg.add_text("â€¢ Classification: Predict categories")
    dpg.add_text("â€¢ Regression: Predict continuous values")
    dpg.add_text("â€¢ Clustering: Find groups in data")

def _create_left_panel():
    """ì¢Œì¸¡ íŒ¨ë„: ë°ì´í„°/ëª¨ë¸ ì„ íƒ"""
    with dpg.child_window(width=250, border=True):
        dpg.add_text("Model Configuration", color=(255, 255, 0))
        dpg.add_separator()
        
        # DataFrame ì„ íƒ
        dpg.add_text("Data Source:")
        dpg.add_combo(
            label="", 
            tag=TAG_S11_DF_SELECTOR,
            callback=_on_df_selected, 
            width=-1,
            items=[]  # ì´ˆê¸°ì—ëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸, update_uiì—ì„œ ì±„ì›Œì§
        )
        
        dpg.add_separator()
        
        # ëª¨ë¸ íƒ€ì… ì„ íƒ
        dpg.add_text("Model Type:")
        dpg.add_radio_button(
            items=["Classification", "Regression", "Clustering"],
            default_value="Classification",
            tag=TAG_S11_MODEL_TYPE_SELECTOR,
            callback=_on_model_type_changed
        )
        
        dpg.add_separator()
        
        # ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
        dpg.add_text("Algorithm:")
        dpg.add_combo(
            label="", 
            tag=TAG_S11_ALGORITHM_SELECTOR,
            items=list(ML_ALGORITHMS["Classification"].keys()),
            default_value="Random Forest",
            callback=_on_algorithm_changed,
            width=-1
        )

def _create_center_panel():
    """ì¤‘ì•™ íŒ¨ë„: ë³€ìˆ˜ ì„ íƒ"""
    with dpg.child_window(width=300, border=True):
        dpg.add_text("Variable Selection", color=(255, 255, 0))
        dpg.add_separator()
        
        # Features ì„ íƒ
        dpg.add_text("Features (Multi-select):")
        with dpg.child_window(height=150, border=True, tag=TAG_S11_FEATURE_LIST):
            # ì´ í•¨ìˆ˜ì—ì„œ ë™ì ìœ¼ë¡œ ìƒì„±ë˜ë¯€ë¡œ ì´ˆê¸° ë‚´ìš©ì€ ë¹„ì›Œë‘¡ë‹ˆë‹¤.
            pass
        
        dpg.add_separator()
        
        # Target ì„ íƒ (supervised learningìš©)
        dpg.add_text("Target Variable:")

        dpg.add_combo(label="", tag=TAG_S11_TARGET_COMBO,
                     items=[""], default_value="", width=-1,
                     callback=_update_variable_lists) 

def _create_right_panel():
    """ìš°ì¸¡ íŒ¨ë„: ì˜µì…˜ ì„¤ì •"""
    with dpg.child_window(border=True):
        dpg.add_text("Training Options", color=(255, 255, 0))
        dpg.add_separator()
        
        # --- â–¼â–¼â–¼â–¼â–¼ ì¶”ê°€ëœ ë¶€ë¶„ â–¼â–¼â–¼â–¼â–¼ ---
        dpg.add_text("Categorical Feature Encoding:")
        dpg.add_radio_button(
            items=["Label Encoding", "One-Hot Encoding"],
            default_value="Label Encoding",
            tag="s11_encoding_method",
            horizontal=True
        )
        dpg.add_separator()
        # --- â–²â–²â–²â–²â–² ì¶”ê°€ëœ ë¶€ë¶„ â–²â–²â–²â–²â–² ---

        # Train/Test Split
        with dpg.group(horizontal=True):
            dpg.add_text("Test Size (%):")
            dpg.add_input_int(default_value=20, min_value=10, max_value=50,
                            tag="s11_test_size", width=100)
        
        with dpg.group(horizontal=True):
            dpg.add_text("Random State:")
            dpg.add_input_int(default_value=42, min_value=0, max_value=9999,
                            tag="s11_random_state", width=100)
        
        dpg.add_checkbox(label="Use Cross-Validation", tag="s11_use_cv")
        dpg.add_checkbox(label="Scale Features", default_value=True, tag="s11_scale_features")
        
        dpg.add_separator()
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì˜ì—­
        dpg.add_text("Hyperparameters:", color=(255, 255, 0))
        with dpg.group(tag=TAG_S11_DYNAMIC_PARAMS_AREA):
            pass
        
        dpg.add_separator()
        
        # ì‹¤í–‰ ë²„íŠ¼
        dpg.add_button(label="Train Model", tag=TAG_S11_TRAIN_BUTTON,
                      callback=_train_model, width=-1, height=30)

def _on_df_selected(sender, app_data, user_data):
    """DataFrame ì„ íƒ ì‹œ"""
    global _selected_df_name, _selected_features
    
    if not app_data:  # app_dataê°€ Noneì´ë©´ ë¦¬í„´
        return
        
    _selected_df_name = app_data
    _selected_features.clear()
    _update_variable_lists()
    
    # ë””ë²„ê·¸ ì¶œë ¥
    print(f"[Step 11] Selected DataFrame: {_selected_df_name}")

def _on_model_type_changed(sender, app_data, user_data):
    """ëª¨ë¸ íƒ€ì… ë³€ê²½ ì‹œ"""
    model_type = app_data
    
    # ì•Œê³ ë¦¬ì¦˜ ëª©ë¡ ì—…ë°ì´íŠ¸
    if dpg.does_item_exist(TAG_S11_ALGORITHM_SELECTOR):
        algorithms = list(ML_ALGORITHMS[model_type].keys())
        dpg.configure_item(TAG_S11_ALGORITHM_SELECTOR, items=algorithms)
        if algorithms:
            dpg.set_value(TAG_S11_ALGORITHM_SELECTOR, algorithms[0])
    
    # Target ë³€ìˆ˜ í‘œì‹œ ì—¬ë¶€
    if dpg.does_item_exist(TAG_S11_TARGET_COMBO):
        show_target = model_type != "Clustering"
        dpg.configure_item(TAG_S11_TARGET_COMBO, show=show_target)
    
    _on_algorithm_changed(None, None, None)

    _update_variable_lists()


def _on_algorithm_changed(sender, app_data, user_data):
    """ì•Œê³ ë¦¬ì¦˜ ë³€ê²½ ì‹œ"""
    _create_hyperparameter_ui()

def _toggle_all_features(sender, app_data, user_data):
    """ëª¨ë“  features ì„ íƒ/í•´ì œ (í™”ë©´ì— ë³´ì´ëŠ” í•„í„°ë§ëœ ë³€ìˆ˜ë§Œ ëŒ€ìƒ)"""
    global _selected_features
    
    if not dpg.does_item_exist(TAG_S11_FEATURE_LIST):
        return

    feature_checkboxes = dpg.get_item_children(TAG_S11_FEATURE_LIST, 1)
    
    # --- â–¼â–¼â–¼â–¼â–¼ ë¬¸ì œ 3 í•´ê²°ì„ ìœ„í•œ ìˆ˜ì • â–¼â–¼â–¼â–¼â–¼ ---
    if app_data:  # "Select All"ì´ ì²´í¬ëœ ê²½ìš°
        for checkbox in feature_checkboxes:
            # "Select All" ìì‹ ì€ ì œì™¸í•˜ê³ , ë³€ìˆ˜ ì²´í¬ë°•ìŠ¤ë§Œ ì²˜ë¦¬
            if dpg.get_item_label(checkbox) != "Select All":
                var_name = dpg.get_item_user_data(checkbox)
                if var_name and var_name not in _selected_features:
                    _selected_features.append(var_name)
    else:  # "Select All"ì´ ì²´í¬ í•´ì œëœ ê²½ìš°
        for checkbox in feature_checkboxes:
             if dpg.get_item_label(checkbox) != "Select All":
                var_name = dpg.get_item_user_data(checkbox)
                if var_name and var_name in _selected_features:
                    _selected_features.remove(var_name)
    
    _update_feature_checkboxes()

def _update_variable_lists():
    """ë³€ìˆ˜ ëª©ë¡ ì—…ë°ì´íŠ¸ (í•„í„°ë§ ë¡œì§ ê°•í™”)"""
    if not _selected_df_name or _selected_df_name not in _available_dfs:
        if dpg.does_item_exist(TAG_S11_FEATURE_LIST):
            dpg.delete_item(TAG_S11_FEATURE_LIST, children_only=True)
        if dpg.does_item_exist(TAG_S11_TARGET_COMBO):
            dpg.configure_item(TAG_S11_TARGET_COMBO, items=[""])
        return

    df = _available_dfs[_selected_df_name]
    all_columns = list(df.columns)

    model_type = dpg.get_value(TAG_S11_MODEL_TYPE_SELECTOR) if dpg.does_item_exist(TAG_S11_MODEL_TYPE_SELECTOR) else "Classification"
    target_col = dpg.get_value(TAG_S11_TARGET_COMBO) if dpg.does_item_exist(TAG_S11_TARGET_COMBO) else None

    s1_analysis_types = {}
    if _module_main_callbacks:
        s1_analysis_types = _module_main_callbacks.get('get_column_analysis_types', lambda: {})()

    eligible_features = all_columns.copy()

    if target_col and target_col in eligible_features:
        eligible_features.remove(target_col)

    eligible_features = [
        var for var in eligible_features
        if s1_analysis_types.get(var) != "ë¶„ì„ì—ì„œ ì œì™¸ (Exclude)"
    ]

    if model_type == "Regression" or model_type == "Clustering":
        numeric_features = []
        for var in eligible_features:
            s1_type = s1_analysis_types.get(var)
            if (s1_type and "Numeric" in s1_type) or pd.api.types.is_numeric_dtype(df[var].dtype):
                numeric_features.append(var)
        eligible_features = numeric_features
    
    # --- â–¼â–¼â–¼â–¼â–¼ ë¬¸ì œ 1 í•´ê²°ì„ ìœ„í•œ ìˆ˜ì • â–¼â–¼â–¼â–¼â–¼ ---
    elif model_type == "Classification":
        classification_features = []
        # ì¹´í…Œê³ ë¦¬í˜• ë³€ìˆ˜ë¡œ ì¸ì •í•  ìµœëŒ€ ê³ ìœ ê°’ ê°œìˆ˜ (ì˜ˆ: 35ê°œ)
        MAX_UNIQUE_FOR_CAT = 35 

        for var in eligible_features:
            s1_type = s1_analysis_types.get(var, "")

            # ID, ê¸´ í…ìŠ¤íŠ¸, ë¯¼ê° ì •ë³´ëŠ” í•­ìƒ ì œì™¸
            if "Text (ID/Code)" in s1_type or "Text (Long/Free)" in s1_type or "Potentially Sensitive" in s1_type:
                continue

            # ìˆ«ìí˜• ë³€ìˆ˜ëŠ” í¬í•¨
            if pd.api.types.is_numeric_dtype(df[var].dtype):
                classification_features.append(var)
            # ì¹´í…Œê³ ë¦¬í˜• ë˜ëŠ” object íƒ€ì…ì´ë©´ì„œ ê³ ìœ ê°’ì´ ì ì€ ê²½ìš°ì—ë§Œ í¬í•¨
            elif df[var].nunique() < MAX_UNIQUE_FOR_CAT:
                 classification_features.append(var)
                 
        eligible_features = classification_features
    # --- â–²â–²â–²â–²â–² ìˆ˜ì • ì™„ë£Œ â–²â–²â–²â–²â–² ---

    if dpg.does_item_exist(TAG_S11_FEATURE_LIST):
        dpg.delete_item(TAG_S11_FEATURE_LIST, children_only=True)
        # "Select All" ì²´í¬ë°•ìŠ¤ë¥¼ ê·¸ë£¹ ë§¨ ìœ„ì— ì¶”ê°€
        dpg.add_checkbox(label="Select All", callback=_toggle_all_features, parent=TAG_S11_FEATURE_LIST)
        dpg.add_separator(parent=TAG_S11_FEATURE_LIST)
        
        for col in eligible_features:
            is_checked = col in _selected_features
            dpg.add_checkbox(label=col,
                           callback=lambda s, a, u: _on_feature_toggle(u, a),
                           user_data=col,
                           parent=TAG_S11_FEATURE_LIST,
                           default_value=is_checked)

    if dpg.does_item_exist(TAG_S11_TARGET_COMBO):
        dpg.configure_item(TAG_S11_TARGET_COMBO, items=[""] + all_columns)
        if target_col and target_col in all_columns:
            dpg.set_value(TAG_S11_TARGET_COMBO, target_col)

def _on_feature_toggle(col_name: str, is_checked: bool):
    """Feature ì²´í¬ë°•ìŠ¤ í† ê¸€"""
    global _selected_features
    
    if is_checked and col_name not in _selected_features:
        _selected_features.append(col_name)
    elif not is_checked and col_name in _selected_features:
        _selected_features.remove(col_name)

def _update_feature_checkboxes():
    """Feature ì²´í¬ë°•ìŠ¤ ìƒíƒœ ì—…ë°ì´íŠ¸"""
    if not dpg.does_item_exist(TAG_S11_FEATURE_LIST):
        return
    
    children = dpg.get_item_children(TAG_S11_FEATURE_LIST, 1)
    for child in children:
        if dpg.get_item_type(child) == "mvAppItemType::mvCheckbox":
            col_name = dpg.get_item_user_data(child)
            if col_name:
                dpg.set_value(child, col_name in _selected_features)

def _create_hyperparameter_ui():
    """í•˜ì´í¼íŒŒë¼ë¯¸í„° UI ìƒì„±"""
    if not dpg.does_item_exist(TAG_S11_DYNAMIC_PARAMS_AREA):
        return
    
    dpg.delete_item(TAG_S11_DYNAMIC_PARAMS_AREA, children_only=True)
    
    algorithm = dpg.get_value(TAG_S11_ALGORITHM_SELECTOR) if dpg.does_item_exist(TAG_S11_ALGORITHM_SELECTOR) else None
    if not algorithm:
        return
    
    # ì•Œê³ ë¦¬ì¦˜ í´ë˜ìŠ¤ ì´ë¦„ ì°¾ê¸°
    model_type = dpg.get_value(TAG_S11_MODEL_TYPE_SELECTOR) if dpg.does_item_exist(TAG_S11_MODEL_TYPE_SELECTOR) else "Classification"
    class_name = ML_ALGORITHMS[model_type][algorithm]["class"]
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
    params = HYPERPARAMETERS.get(class_name, {})
    
    for param_name, param_info in params.items():
        with dpg.group(horizontal=True, parent=TAG_S11_DYNAMIC_PARAMS_AREA):
            dpg.add_text(f"{param_name}:")
            
            tag = f"s11_param_{param_name}"
            
            if param_info["type"] == "int":
                dpg.add_input_int(
                    default_value=param_info["default"],
                    min_value=param_info["min"],
                    max_value=param_info["max"],
                    tag=tag,
                    width=100
                )
            elif param_info["type"] == "float":
                dpg.add_input_float(
                    default_value=param_info["default"],
                    min_value=param_info["min"],
                    max_value=param_info["max"],
                    tag=tag,
                    width=100,
                    format="%.4f"
                )
            elif param_info["type"] == "combo":
                dpg.add_combo(
                    items=param_info["options"],
                    default_value=param_info["default"],
                    tag=tag,
                    width=100
                )
            elif param_info["type"] == "text":
                dpg.add_input_text(
                    default_value=param_info["default"],
                    hint=param_info.get("hint", ""),
                    tag=tag,
                    width=150
                )

def _train_model():
    """ëª¨ë¸ í•™ìŠµ"""
    try:
        # Progress modal í‘œì‹œ
        _util_funcs['show_dpg_progress_modal']("Training Model", "Preparing data...")
        
        # ë°ì´í„° í™•ì¸
        if not _selected_df_name:
            raise ValueError("Please select a DataFrame")
            
        if _selected_df_name not in _available_dfs:
            raise ValueError(f"Selected DataFrame '{_selected_df_name}' not found")
            
        if not _selected_features:
            raise ValueError("Please select at least one feature")
        
        df = _available_dfs[_selected_df_name]
        model_type = dpg.get_value(TAG_S11_MODEL_TYPE_SELECTOR)
        algorithm = dpg.get_value(TAG_S11_ALGORITHM_SELECTOR)
        
        # ë””ë²„ê·¸ ì¶œë ¥
        print(f"[Step 11] Training with:")
        print(f"  - DataFrame: {_selected_df_name} (shape: {df.shape})")
        print(f"  - Features: {_selected_features}")
        print(f"  - Model Type: {model_type}")
        print(f"  - Algorithm: {algorithm}")
        
        # Features ì¶”ì¶œ
        X = df[_selected_features].copy()
        
        encoding_method = dpg.get_value("s11_encoding_method") if dpg.does_item_exist("s11_encoding_method") else "Label Encoding"
        encoders = {} # LabelEncoder ì •ë³´ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬

        if encoding_method == "One-Hot Encoding":
            # ì›-í•« ì¸ì½”ë”© ì ìš©
            print("[Step 11] Applying One-Hot Encoding...")
            # ì¸ì½”ë”©í•  ë²”ì£¼í˜• ë³€ìˆ˜ ì‹ë³„ (object íƒ€ì…)
            categorical_cols = X.select_dtypes(include=['object', 'category']).columns
            if not categorical_cols.empty:
                X = pd.get_dummies(X, columns=categorical_cols, drop_first=True, dtype=float)
        
        else: # Label Encoding (ê¸°ë³¸ê°’)
            # ë ˆì´ë¸” ì¸ì½”ë”© ì ìš© (ê¸°ì¡´ ë¡œì§)
            print("[Step 11] Applying Label Encoding...")
            for col in X.select_dtypes(include=['object', 'category']).columns:
                le = LabelEncoder()
                X[col] = le.fit_transform(X[col].astype(str).fillna('missing'))
                encoders[col] = le
        
        # Target ì¶”ì¶œ (supervised learning)
        y = None
        if model_type != "Clustering":
            target_col = dpg.get_value(TAG_S11_TARGET_COMBO)
            if not target_col:
                raise ValueError("Please select target variable")
            
            y = df[target_col].copy()
            if y.dtype == 'object' or model_type == "Classification":
                le = LabelEncoder()
                y = le.fit_transform(y)
                encoders['target'] = le
        
        # ìŠ¤ì¼€ì¼ë§
        scaler = None
        if dpg.get_value("s11_scale_features"):
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
        else:
            X_scaled = X.values
        
        # ëª¨ë¸ ìƒì„±
        model_info = ML_ALGORITHMS[model_type][algorithm]
        module = __import__(model_info["module"], fromlist=[model_info["class"]])
        model_class = getattr(module, model_info["class"])
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìˆ˜ì§‘
        hyperparams = _get_hyperparameters(model_info["class"])
        model = model_class(**hyperparams)
        
        # í•™ìŠµ
        _util_funcs['show_dpg_progress_modal']("Training Model", "Training in progress...")
        
        if model_type == "Clustering":
            # í´ëŸ¬ìŠ¤í„°ë§
            labels = model.fit_predict(X_scaled)
            results = _evaluate_clustering(model, X_scaled, labels)
        else:
            # ë¶„ë¥˜/íšŒê·€
            test_size = dpg.get_value("s11_test_size") / 100.0
            random_state = dpg.get_value("s11_random_state")
            
            X_train, X_test, y_train, y_test = train_test_split(
                X_scaled, y, test_size=test_size, random_state=random_state
            )
            
            model.fit(X_train, y_train)
            
            if dpg.get_value("s11_use_cv"):
                cv_scores = cross_val_score(model, X_scaled, y, cv=5)
            else:
                cv_scores = None
            
            results = _evaluate_model(model, X_train, X_test, y_train, y_test, 
                                    model_type, cv_scores, encoders)
        
        # ê²°ê³¼ ì €ì¥
        global _model_counter
        _model_counter += 1
        model_name = f"{algorithm}_{_model_counter}"
        
        _trained_models[model_name] = {
            'model': model,
            'scaler': scaler,
            'encoders': encoders,
            'features': _selected_features,
            'results': results,
            'type': model_type,
            'algorithm': algorithm,
            'X': X,
            'y': y
        }
        
        # ê²°ê³¼ í‘œì‹œ
        _create_results_tab(model_name, results)
        
        _util_funcs['_show_simple_modal_message']("Success", 
            f"Model '{model_name}' trained successfully!")
        
    except Exception as e:
        _util_funcs['_show_simple_modal_message']("Training Error", str(e))
        traceback.print_exc()
    
    finally:
        _util_funcs['hide_dpg_progress_modal']()

def _get_hyperparameters(class_name: str) -> dict:
    """UIì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ ìˆ˜ì§‘"""
    params = {}
    param_defs = HYPERPARAMETERS.get(class_name, {})
    
    for param_name, param_info in param_defs.items():
        tag = f"s11_param_{param_name}"
        if dpg.does_item_exist(tag):
            value = dpg.get_value(tag)
            
            # íŠ¹ìˆ˜ ì²˜ë¦¬
            if param_name == "hidden_layer_sizes" and isinstance(value, str):
                # "100,50" -> (100, 50)
                try:
                    value = tuple(map(int, value.split(',')))
                except:
                    value = (100,)
            
            params[param_name] = value
    
    return params

def _evaluate_model(model, X_train, X_test, y_train, y_test, model_type, cv_scores, encoders):
    """ëª¨ë¸ í‰ê°€"""
    results = {
        'model_type': model_type,
        'train_size': len(X_train),
        'test_size': len(X_test)
    }
    
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)
    
    if model_type == "Classification":
        # ë¶„ë¥˜ í‰ê°€
        results['train_accuracy'] = accuracy_score(y_train, y_pred_train)
        results['test_accuracy'] = accuracy_score(y_test, y_pred_test)
        
        # Precision, Recall, F1
        prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred_test, average='weighted')
        results['precision'] = prec
        results['recall'] = rec
        results['f1_score'] = f1
        
        # í˜¼ë™ í–‰ë ¬
        results['confusion_matrix'] = confusion_matrix(y_test, y_pred_test)
        
        # í´ë˜ìŠ¤ ì´ë¦„
        if 'target' in encoders:
            results['class_names'] = encoders['target'].classes_
        
        # í™•ë¥  ì˜ˆì¸¡ (ê°€ëŠ¥í•œ ê²½ìš°)
        if hasattr(model, 'predict_proba'):
            results['y_prob_test'] = model.predict_proba(X_test)
    
    else:  # Regression
        # íšŒê·€ í‰ê°€
        results['train_r2'] = r2_score(y_train, y_pred_train)
        results['test_r2'] = r2_score(y_test, y_pred_test)
        results['train_rmse'] = np.sqrt(mean_squared_error(y_train, y_pred_train))
        results['test_rmse'] = np.sqrt(mean_squared_error(y_test, y_pred_test))
        results['train_mae'] = mean_absolute_error(y_train, y_pred_train)
        results['test_mae'] = mean_absolute_error(y_test, y_pred_test)
    
    # CV ì ìˆ˜
    if cv_scores is not None:
        results['cv_scores'] = cv_scores
        results['cv_mean'] = cv_scores.mean()
        results['cv_std'] = cv_scores.std()
    
    # ì˜ˆì¸¡ê°’ ì €ì¥
    results['y_test'] = y_test
    results['y_pred_test'] = y_pred_test
    
    # Feature importance (ê°€ëŠ¥í•œ ê²½ìš°)
    if hasattr(model, 'feature_importances_'):
        results['feature_importances'] = model.feature_importances_
        results['feature_names'] = _selected_features
    
    return results

def _evaluate_clustering(model, X, labels):
    """í´ëŸ¬ìŠ¤í„°ë§ í‰ê°€"""
    from sklearn.metrics import silhouette_score, davies_bouldin_score
    
    results = {
        'model_type': 'Clustering',
        'n_samples': len(X),
        'labels': labels
    }
    
    # í´ëŸ¬ìŠ¤í„° ê°œìˆ˜
    n_clusters = len(np.unique(labels[labels != -1]))  # -1ì€ ë…¸ì´ì¦ˆ
    results['n_clusters'] = n_clusters
    
    if n_clusters > 1:
        # ì‹¤ë£¨ì—£ ì ìˆ˜
        mask = labels != -1  # ë…¸ì´ì¦ˆ ì œì™¸
        if mask.sum() > 0:
            results['silhouette_score'] = silhouette_score(X[mask], labels[mask])
            results['davies_bouldin_score'] = davies_bouldin_score(X[mask], labels[mask])
    
    # í´ëŸ¬ìŠ¤í„°ë³„ í¬ê¸°
    unique_labels, counts = np.unique(labels, return_counts=True)
    results['cluster_sizes'] = dict(zip(unique_labels, counts))
    
    # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ (K-Meansì˜ ê²½ìš°)
    if hasattr(model, 'cluster_centers_'):
        results['cluster_centers'] = model.cluster_centers_
    
    return results

def _create_results_tab(model_name: str, results: Dict[str, Any]):
    """ê²°ê³¼ íƒ­ ìƒì„±"""
    if not dpg.does_item_exist(TAG_S11_VIZ_TAB_BAR):
        return
    
    with dpg.tab(label=model_name, parent=TAG_S11_VIZ_TAB_BAR, closable=True):
        with dpg.child_window(border=False):
            # ëª¨ë¸ ì •ë³´
            dpg.add_text(f"Model: {model_name}", color=(255, 255, 0))
            dpg.add_separator()
            
            # ì„±ëŠ¥ ì§€í‘œ
            _create_performance_metrics(results)
            dpg.add_separator()
            
            # ì‹œê°í™”
            _create_visualizations(results)
            
            # Export ë²„íŠ¼
            dpg.add_separator()
            with dpg.group(horizontal=True):
                dpg.add_button(label="Save Model", 
                             callback=lambda: _save_model(model_name))
                dpg.add_button(label="Export Results", 
                             callback=lambda: _export_results(model_name))

def _create_performance_metrics(results: Dict[str, Any]):
    """ì„±ëŠ¥ ì§€í‘œ í‘œì‹œ"""
    model_type = results['model_type']
    
    if model_type == "Classification":
        dpg.add_text("Classification Metrics:", color=(255, 255, 0))
        dpg.add_text(f"Train Accuracy: {results['train_accuracy']:.4f}")
        dpg.add_text(f"Test Accuracy: {results['test_accuracy']:.4f}")
        dpg.add_text(f"Precision: {results['precision']:.4f}")
        dpg.add_text(f"Recall: {results['recall']:.4f}")
        dpg.add_text(f"F1-Score: {results['f1_score']:.4f}")
        
        if 'cv_mean' in results:
            dpg.add_text(f"CV Score: {results['cv_mean']:.4f} (+/- {results['cv_std']:.4f})")
    
    elif model_type == "Regression":
        dpg.add_text("Regression Metrics:", color=(255, 255, 0))
        dpg.add_text(f"Train RÂ²: {results['train_r2']:.4f}")
        dpg.add_text(f"Test RÂ²: {results['test_r2']:.4f}")
        dpg.add_text(f"Train RMSE: {results['train_rmse']:.4f}")
        dpg.add_text(f"Test RMSE: {results['test_rmse']:.4f}")
        dpg.add_text(f"Train MAE: {results['train_mae']:.4f}")
        dpg.add_text(f"Test MAE: {results['test_mae']:.4f}")
        
        if 'cv_mean' in results:
            dpg.add_text(f"CV Score: {results['cv_mean']:.4f} (+/- {results['cv_std']:.4f})")
    
    elif model_type == "Clustering":
        dpg.add_text("Clustering Metrics:", color=(255, 255, 0))
        dpg.add_text(f"Number of Clusters: {results['n_clusters']}")
        
        if 'silhouette_score' in results:
            dpg.add_text(f"Silhouette Score: {results['silhouette_score']:.4f}")
        if 'davies_bouldin_score' in results:
            dpg.add_text(f"Davies-Bouldin Score: {results['davies_bouldin_score']:.4f}")
        
        dpg.add_text("Cluster Sizes:")
        for label, size in results['cluster_sizes'].items():
            cluster_name = f"Cluster {label}" if label != -1 else "Noise"
            dpg.add_text(f"  {cluster_name}: {size}")

def _create_visualizations(results: Dict[str, Any]):
    """ì‹œê°í™” ìƒì„±"""
    model_type = results['model_type']
    plot_func = _util_funcs.get('plot_to_dpg_texture')
    
    if not plot_func:
        return
    
    if model_type == "Classification":
        # í˜¼ë™ í–‰ë ¬
        fig, ax = plt.subplots(figsize=(8, 6))
        cm = results['confusion_matrix']
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
        ax.set_xlabel('Predicted')
        ax.set_ylabel('Actual')
        ax.set_title('Confusion Matrix')
        
        _add_plot_to_ui(fig, plot_func, "Confusion Matrix")
        
        # Feature Importance
        if 'feature_importances' in results:
            fig, ax = plt.subplots(figsize=(10, 6))
            features = results['feature_names']
            importances = results['feature_importances']
            indices = np.argsort(importances)[::-1][:10]  # Top 10
            
            ax.bar(range(len(indices)), importances[indices])
            ax.set_xticks(range(len(indices)))
            ax.set_xticklabels([features[i] for i in indices], rotation=45)
            ax.set_title('Top 10 Feature Importances')
            
            _add_plot_to_ui(fig, plot_func, "Feature Importance")
    
    elif model_type == "Regression":
        # ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’
        fig, ax = plt.subplots(figsize=(8, 6))
        ax.scatter(results['y_test'], results['y_pred_test'], alpha=0.6)
        ax.plot([results['y_test'].min(), results['y_test'].max()], 
               [results['y_test'].min(), results['y_test'].max()], 
               'r--', lw=2)
        ax.set_xlabel('Actual')
        ax.set_ylabel('Predicted')
        ax.set_title('Actual vs Predicted')
        
        _add_plot_to_ui(fig, plot_func, "Actual vs Predicted")
        
        # ì”ì°¨ í”Œë¡¯
        fig, ax = plt.subplots(figsize=(8, 6))
        residuals = results['y_test'] - results['y_pred_test']
        ax.scatter(results['y_pred_test'], residuals, alpha=0.6)
        ax.axhline(y=0, color='r', linestyle='--')
        ax.set_xlabel('Predicted')
        ax.set_ylabel('Residuals')
        ax.set_title('Residual Plot')
        
        _add_plot_to_ui(fig, plot_func, "Residual Plot")
    
    elif model_type == "Clustering":
        # í´ëŸ¬ìŠ¤í„° ë¶„í¬ (2D íˆ¬ì˜)
        from sklearn.decomposition import PCA
        
        # PCAë¡œ 2D íˆ¬ì˜
        X = _trained_models[list(_trained_models.keys())[-1]]['X']
        if X.shape[1] > 2:
            pca = PCA(n_components=2)
            X_2d = pca.fit_transform(X)
        else:
            X_2d = X.values
        
        fig, ax = plt.subplots(figsize=(8, 6))
        scatter = ax.scatter(X_2d[:, 0], X_2d[:, 1], 
                           c=results['labels'], cmap='viridis', 
                           alpha=0.6)
        plt.colorbar(scatter, ax=ax)
        ax.set_xlabel('Component 1')
        ax.set_ylabel('Component 2')
        ax.set_title('Cluster Visualization (2D PCA)')
        
        _add_plot_to_ui(fig, plot_func, "Cluster Visualization")

def _add_plot_to_ui(fig, plot_func, title: str):
    """í”Œë¡¯ì„ UIì— ì¶”ê°€"""
    tex_tag, w, h, img_bytes = plot_func(fig)
    
    if tex_tag:
        dpg.add_text(title)
        dpg.add_image(tex_tag, width=w, height=h)
        
        # AI ë¶„ì„ ë²„íŠ¼
        if img_bytes and _module_main_callbacks:
            import utils
            ai_button_tag = dpg.generate_uuid()
            action_callback = lambda: utils.confirm_and_run_ai_analysis(
                img_bytes, f"ML Model - {title}", ai_button_tag, _module_main_callbacks
            )
            dpg.add_button(label=f"ğŸ’¡ Analyze {title}", tag=ai_button_tag,
                         callback=action_callback)
    
    plt.close(fig)
    dpg.add_separator()

def _save_model(model_name: str):
    """ëª¨ë¸ ì €ì¥"""
    import pickle
    import datetime
    
    try:
        model_data = _trained_models[model_name]
        filename = f"{model_name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
        
        # íŒŒì¼ ë‹¤ì´ì–¼ë¡œê·¸ë¡œ ì €ì¥ ìœ„ì¹˜ ì„ íƒ
        with dpg.file_dialog(
            directory_selector=False, show=True,
            callback=lambda s, a: _do_save_model(a['file_path_name'], model_data),
            default_filename=filename, width=700, height=400, modal=True
        ):
            dpg.add_file_extension(".pkl", color=(0, 255, 0, 255))
            
    except Exception as e:
        _util_funcs['_show_simple_modal_message']("Save Error", str(e))

def _do_save_model(filepath: str, model_data: dict):
    """ì‹¤ì œ ëª¨ë¸ ì €ì¥"""
    import pickle
    
    try:
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
        
        _util_funcs['_show_simple_modal_message']("Success", 
            f"Model saved to:\n{filepath}")
    except Exception as e:
        _util_funcs['_show_simple_modal_message']("Save Error", str(e))

def _export_results(model_name: str):
    """ê²°ê³¼ ë‚´ë³´ë‚´ê¸°"""
    # Excelë¡œ ë‚´ë³´ë‚´ê¸° êµ¬í˜„
    _util_funcs['_show_simple_modal_message']("Info", 
        "Export functionality coming soon!")

def update_ui():
    """UI ì—…ë°ì´íŠ¸"""
    global _available_dfs
    
    if not _module_main_callbacks:
        return
    
    # DataFrame ëª©ë¡ ê°€ì ¸ì˜¤ê¸° - Step 10ê³¼ ë™ì¼í•œ íŒ¨í„´
    all_dfs_from_main = _module_main_callbacks.get('get_all_available_dfs', lambda: {})()
    
    # Original Data ì œì™¸ (Step 10ê³¼ ë™ì¼)
    _available_dfs = {k: v for k, v in all_dfs_from_main.items() if k != '0. Original Data'}
    
    if dpg.does_item_exist(TAG_S11_DF_SELECTOR):
        df_names = list(_available_dfs.keys())
        current = dpg.get_value(TAG_S11_DF_SELECTOR)
        
        dpg.configure_item(TAG_S11_DF_SELECTOR, items=df_names)
        
        # í˜„ì¬ ì„ íƒì´ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ì²« ë²ˆì§¸ í•­ëª© ì„ íƒ
        if current not in df_names:
            new_selection = df_names[0] if df_names else ""
            dpg.set_value(TAG_S11_DF_SELECTOR, new_selection)
            if new_selection:
                _on_df_selected(None, new_selection, None)

def reset_state():
    """ìƒíƒœ ì´ˆê¸°í™”"""
    global _selected_df_name, _selected_features, _trained_models, _model_counter
    
    _selected_df_name = ""
    _selected_features.clear()
    _trained_models.clear()
    _model_counter = 0
    
    # UI ì´ˆê¸°í™”
    if dpg.is_dearpygui_running():
        if dpg.does_item_exist(TAG_S11_VIZ_TAB_BAR):
            tabs = dpg.get_item_children(TAG_S11_VIZ_TAB_BAR, 1)
            for tab in tabs[1:]:  # Guide íƒ­ ì œì™¸
                if dpg.does_item_exist(tab):
                    dpg.delete_item(tab)
        
        update_ui()