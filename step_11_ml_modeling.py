# step_11_ml_modeling.py

import dearpygui.dearpygui as dpg
import sys
import pandas as pd

print("--- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ í™˜ê²½ ì •ë³´ ---")
print(f"íŒŒì´ì¬ ì‹¤í–‰ ê²½ë¡œ: {sys.executable}")
print(f"Pandas ë²„ì „: {pd.__version__}")
print("---------------------------------")

import numpy as np
from typing import Dict, List, Optional, Any, Tuple
import traceback
import datetime
import uuid
import threading
import queue
import time
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import os
import shutil

# [NEW] AutoGluon ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from autogluon.tabular import TabularPredictor
import shap

AUTOGLUON_AVAILABLE = True
SHAP_AVAILABLE = True

warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)

# --- DPG Tags ---
TAG_S11_GROUP = "step11_ml_modeling_group"
TAG_S11_MAIN_TAB_BAR = "step11_main_tab_bar"
TAG_S11_MODELING_TAB = "step11_modeling_tab"
TAG_S11_INFERENCE_TAB = "step11_inference_tab"

# Modeling Tab UI Tags
TAG_S11_DF_SELECTOR = "step11_df_selector"
TAG_S11_TARGET_SELECTOR = "step11_target_selector"
TAG_S11_TASK_TYPE_TEXT = "s11_detected_task_text"
TAG_S11_RUN_BUTTON = "step11_run_button"
TAG_S11_LEADERBOARD_TABLE = "step11_leaderboard_table"
TAG_S11_DEEP_DIVE_GROUP = "step11_deep_dive_group"
TAG_S11_LOG_TEXT = "step11_log_text"
TAG_S11_LOG_WINDOW = "step11_log_window"
TAG_S11_PROGRESS_BAR = "step11_progress_bar"

# AutoGluon ê´€ë ¨ UI Tags
TAG_S11_PRESET_SELECTOR = "step11_preset_selector"
TAG_S11_TIME_LIMIT_INPUT = "step11_time_limit_input"

# Inference Tags
TAG_S11_INFERENCE_MODEL_DIALOG = "s11_inference_model_file_dialog"
TAG_S11_INFERENCE_DATA_DIALOG = "s11_inference_data_file_dialog"
TAG_S11_INFERENCE_SAVE_DIALOG = "s11_inference_save_file_dialog"

# [ìˆ˜ì •] Plotting ë° SHAP ê´€ë ¨ Tags
TAG_S11_RESULTS_TAB_BAR = "s11_results_tab_bar"
TAG_S11_LEADERBOARD_TAB = "s11_leaderboard_tab"
TAG_S11_DEEP_DIVE_TAB = "s11_deep_dive_tab"
TAG_S11_PERFORMANCE_PLOT_WINDOW = "s11_performance_plot_window" # í”¼ì²˜ ì¤‘ìš”ë„ í”Œë¡¯ìš©
TAG_S11_PERFORMANCE_PLOT_IMAGE = "s11_performance_plot_image"
TAG_S11_SHAP_DASHBOARD_WINDOW = "s11_shap_dashboard_window" # [ì‹ ê·œ] SHAP ëŒ€ì‹œë³´ë“œìš©
TAG_S11_SHAP_DASHBOARD_PLACEHOLDER = "s11_shap_dashboard_placeholder" # [ì‹ ê·œ] SHAP ëŒ€ì‹œë³´ë“œ í”Œë ˆì´ìŠ¤í™€ë”


# --- Module State ---
_module_main_callbacks: Optional[Dict] = None
_util_funcs: Optional[Dict[str, Any]] = None
_texture_tags: List[str] = []
_results_queue = queue.Queue()
_worker_thread: Optional[threading.Thread] = None

_leaderboard_results: List[Dict] = []
_current_deep_dive_model_name: Optional[str] = None
_current_predictor_path: Optional[str] = None
_current_predictor: Optional[TabularPredictor] = None

_inference_predictor: Optional[TabularPredictor] = None
_inference_df: Optional[pd.DataFrame] = None
_inference_result_df: Optional[pd.DataFrame] = None

# --- ìœ í‹¸ë¦¬í‹° ë° ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… í•¨ìˆ˜ë“¤ (ê¸°ì¡´ê³¼ ê±°ì˜ ë™ì¼) ---

def _log_message(message: str, level: str = "INFO"):
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    if not dpg.is_dearpygui_running() or not dpg.does_item_exist(TAG_S11_LOG_TEXT): return
    timestamp = datetime.datetime.now().strftime("%H:%M:%S")
    formatted_msg = f"[{timestamp}] {level}: {message}"
    current_log = dpg.get_value(TAG_S11_LOG_TEXT)
    if "AutoGluon í›ˆë ¨ì„ ì‹œì‘í•˜ì„¸ìš”." in current_log: current_log = ""
    new_log = f"{current_log}\n{formatted_msg}"
    if len(new_log) > 20000: new_log = new_log[-20000:]
    dpg.set_value(TAG_S11_LOG_TEXT, new_log)
    if dpg.does_item_exist(TAG_S11_LOG_WINDOW): dpg.set_y_scroll(TAG_S11_LOG_WINDOW, dpg.get_y_scroll_max(TAG_S11_LOG_WINDOW))

def _start_background_task(target_func, args=()):
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    global _worker_thread
    if not AUTOGLUON_AVAILABLE:
        _util_funcs['_show_simple_modal_message']("ì˜¤ë¥˜", "AutoGluonì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. AutoML ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    if _worker_thread and _worker_thread.is_alive():
        _util_funcs['_show_simple_modal_message']("ì‘ì—… ì¤‘", "ì´ì „ ì‘ì—…ì´ ì•„ì§ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."); return
    _worker_thread = threading.Thread(target=target_func, args=args, daemon=True)
    _worker_thread.start()
    _update_progress(0.0, "ì‘ì—…ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤...")

def _run_autogluon_fit_thread(df: pd.DataFrame, target_name: str, preset: str, time_limit: int):
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    global _current_predictor_path, _current_predictor
    try:
        _results_queue.put({"type": "progress", "value": 0.05, "log": "AutoGluon ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„ ì¤‘..."})
        output_dir_base = "autogluon_models"
        if os.path.exists(output_dir_base):
             shutil.rmtree(output_dir_base)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_path = os.path.join(output_dir_base, f"ag_{timestamp}")
        predictor = TabularPredictor(label=target_name, path=save_path, problem_type=None)
        _results_queue.put({"type": "progress", "value": 0.1, "log": f"'{preset}' í”„ë¦¬ì…‹ìœ¼ë¡œ ëª¨ë¸ í›ˆë ¨ ì‹œì‘ (ì‹œê°„ ì œí•œ: {time_limit}ì´ˆ)..."})
        predictor.fit(train_data=df, presets=preset, time_limit=time_limit)
        _results_queue.put({"type": "progress", "value": 0.9, "log": "ë¦¬ë”ë³´ë“œ ìƒì„± ì¤‘..."})
        leaderboard_df = predictor.leaderboard(df, silent=True)
        _current_predictor_path = predictor.path
        _current_predictor = predictor
        _results_queue.put({
            "type": "autogluon_result",
            "leaderboard": leaderboard_df.to_dict('records'),
            "predictor_path": predictor.path
        })
    except Exception as e:
        error_msg = f"AutoGluon í›ˆë ¨ ì˜¤ë¥˜: {str(e)}\n{traceback.format_exc()}"
        _results_queue.put({"type": "error", "log": error_msg})

def _run_feature_importance_thread():
    # (ê¸°ì¡´ ì½”ë“œì™€ ê±°ì˜ ë™ì¼, ê²°ê³¼ íƒ€ì…ë§Œ ë³€ê²½)
    try:
        if not _current_predictor:
            _results_queue.put({"type": "error", "log": "ë¶„ì„í•  Predictorê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}); return
        _results_queue.put({"type": "progress", "value": 0.1, "log": "í”¼ì²˜ ì¤‘ìš”ë„ ê³„ì‚° ì¤‘..."})
        df_name = dpg.get_value(TAG_S11_DF_SELECTOR)
        all_dfs = _module_main_callbacks.get('get_all_available_dfs', lambda: {})()
        data_for_analysis = all_dfs.get(df_name)
        if data_for_analysis is None: raise ValueError(f"'{df_name}' ë°ì´í„°í”„ë ˆì„ì„ í˜„ì¬ ìƒíƒœì—ì„œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        feature_importance_df = _current_predictor.feature_importance(data=data_for_analysis, feature_stage='original')
        _results_queue.put({"type": "progress", "value": 0.8, "log": "í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™” ìƒì„± ì¤‘..."})
        plt.style.use('seaborn-v0_8-darkgrid')
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.barplot(x=feature_importance_df['importance'].head(20), y=feature_importance_df.index[:20], ax=ax)
        ax.set_title('Feature Importance (Permutation)', fontsize=16); ax.set_xlabel('Importance Score', fontsize=12); ax.set_ylabel('Features', fontsize=12)
        plt.tight_layout()
        texture_tag, width, height, _ = (None, 0, 0, None)
        if _util_funcs and 'plot_to_dpg_texture' in _util_funcs: texture_tag, width, height, _ = _util_funcs['plot_to_dpg_texture'](fig)
        plt.close(fig)
        if texture_tag:
            # [ìˆ˜ì •] í”¼ì²˜ ì¤‘ìš”ë„ í”Œë¡¯ ì „ìš© ê²°ê³¼ íƒ€ì…ì„ ì‚¬ìš©
            _results_queue.put({"type": "performance_plot_result", "texture_tag": texture_tag, "width": width, "height": height})
        else:
            _results_queue.put({"type": "error", "log": "í”¼ì²˜ ì¤‘ìš”ë„ í”Œë¡¯ì„ DPG í…ìŠ¤ì²˜ë¡œ ë³€í™˜í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."})
    except Exception as e:
        error_msg = f"í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}\n{traceback.format_exc()}"
        _results_queue.put({"type": "error", "log": error_msg})

def create_ui(step_name: str, parent_container_tag: str, main_callbacks: dict):
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    global _module_main_callbacks, _util_funcs
    _module_main_callbacks = main_callbacks
    _util_funcs = main_callbacks.get('get_util_funcs', lambda: {})()
    main_callbacks['register_step_group_tag'](step_name, TAG_S11_GROUP)
    with dpg.file_dialog(directory_selector=True, show=False, callback=_on_model_dir_selected, id=TAG_S11_INFERENCE_MODEL_DIALOG, width=700, height=400, modal=True): pass
    with dpg.file_dialog(directory_selector=False, show=False, callback=_on_inference_data_selected, id=TAG_S11_INFERENCE_DATA_DIALOG, width=700, height=400, modal=True):
        dpg.add_file_extension(".csv"); dpg.add_file_extension(".parquet")
    with dpg.file_dialog(directory_selector=False, show=False, callback=_on_save_inference_result_selected, id=TAG_S11_INFERENCE_SAVE_DIALOG, width=700, height=400, modal=True, default_filename="predictions.csv"):
        dpg.add_file_extension(".csv", color=(0, 255, 0, 255))
    with dpg.group(tag=TAG_S11_GROUP, parent=parent_container_tag, show=False):
        dpg.add_text(f"--- {step_name} (Powered by AutoGluon) ---"); dpg.add_separator()
        with dpg.tab_bar(tag=TAG_S11_MAIN_TAB_BAR):
            with dpg.tab(label="ëª¨ë¸ë§ (Modeling)", tag=TAG_S11_MODELING_TAB):
                _create_modeling_tab_ui()
            with dpg.tab(label="ì¶”ë¡  (Inference)", tag=TAG_S11_INFERENCE_TAB):
                _create_inference_tab_ui()
    main_callbacks['register_module_updater'](step_name, update_ui)

def _create_modeling_tab_ui():
    with dpg.group(tag="s11_modeling_main_group"):
        with dpg.group(horizontal=True):
            # --- ì¢Œì¸¡ ì„¤ì • íŒ¨ë„ ---
            with dpg.group(width=200):
                dpg.add_text("1. ì„¤ì • (Setup)", color=(255, 255, 0)); dpg.add_separator()
                dpg.add_text("ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ:"); dpg.add_combo(label="", tag=TAG_S11_DF_SELECTOR, width=-1, callback=_on_df_or_target_selected)
                dpg.add_text("íƒ€ê²Ÿ ë³€ìˆ˜ (y) ì„ íƒ:"); dpg.add_combo(label="", tag=TAG_S11_TARGET_SELECTOR, width=-1, callback=_on_df_or_target_selected)
                with dpg.group(horizontal=True):
                    dpg.add_text("ê°ì§€ëœ íƒœìŠ¤í¬ íƒ€ì…:"); dpg.add_text("(ë°ì´í„° ì„ íƒ)", tag=TAG_S11_TASK_TYPE_TEXT, color=(255, 255, 0))
                dpg.add_separator()
                dpg.add_text("2. AutoGluon ì„¤ì •", color=(255, 255, 0))
                dpg.add_text("í’ˆì§ˆ í”„ë¦¬ì…‹ (Quality Preset):"); dpg.add_combo(items=['best_quality', 'high_quality', 'good_quality', 'medium_quality'], default_value="medium_quality", width=-1, tag=TAG_S11_PRESET_SELECTOR)
                dpg.add_text("í›ˆë ¨ ì‹œê°„ ì œí•œ (ì´ˆ):"); dpg.add_input_int(default_value=60, width=-1, tag=TAG_S11_TIME_LIMIT_INPUT, min_value=10, min_clamped=True)
                dpg.add_spacer(height=10)
                dpg.add_button(label="ğŸš€ AutoGluon í›ˆë ¨ ì‹¤í–‰", tag=TAG_S11_RUN_BUTTON, width=-1, height=40, callback=_start_autogluon_fit_callback)
            
            # --- ìš°ì¸¡ ê²°ê³¼ íŒ¨ë„ (íƒ­ êµ¬ì¡°) ---
            with dpg.group(): 
                with dpg.tab_bar(tag=TAG_S11_RESULTS_TAB_BAR):
                    # --- ë¦¬ë”ë³´ë“œ íƒ­ ---
                    with dpg.tab(label="ë¦¬ë”ë³´ë“œ", tag=TAG_S11_LEADERBOARD_TAB):
                        dpg.add_text("ëª¨ë¸ ì„±ëŠ¥ ë¦¬ë”ë³´ë“œ", color=(255, 255, 0))
                        dpg.add_table(tag=TAG_S11_LEADERBOARD_TABLE, header_row=True, resizable=True, reorderable=True, borders_innerV=True, borders_outerH=True, height=600, scrollX=True, policy=dpg.mvTable_SizingFixedFit)
                    
                    # --- [ìˆ˜ì •] ì‹¬ì¸µ ë¶„ì„ íƒ­ UI ì¬êµ¬ì„± ---
                    with dpg.tab(label="ì‹¬ì¸µ ë¶„ì„", tag=TAG_S11_DEEP_DIVE_TAB):
                        with dpg.group(tag=TAG_S11_DEEP_DIVE_GROUP, show=False):
                            dpg.add_text("Selected Model: ", tag="s11_deep_dive_model_name"); dpg.add_separator()
                            with dpg.tab_bar():
                                with dpg.tab(label="ì„±ëŠ¥ (Performance)"):
                                    dpg.add_text("ëª¨ë¸ì˜ ìƒì„¸ ì„±ëŠ¥ ì§€í‘œì…ë‹ˆë‹¤.")
                                    with dpg.table(tag="s11_deep_dive_perf_table", header_row=True, height=300):
                                        dpg.add_table_column(label="Metric"); dpg.add_table_column(label="Value")
                                
                                with dpg.tab(label="í”¼ì²˜ ì¤‘ìš”ë„ (Feature Importance)"):
                                    dpg.add_text("ëª¨ë¸ì´ ì˜ˆì¸¡ì— ì¤‘ìš”í•˜ê²Œ ì‚¬ìš©í•œ í”¼ì²˜ ëª©ë¡ì…ë‹ˆë‹¤. (Permutation Importance)", wrap=500)
                                    dpg.add_button(label="í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ ì‹¤í–‰", callback=_run_feature_importance_analysis)
                                    dpg.add_separator()
                                    with dpg.child_window(tag=TAG_S11_PERFORMANCE_PLOT_WINDOW, border=True, height=-1):
                                        dpg.add_text("ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.", tag="s11_perf_plot_placeholder")

                                # --- [ì‹ ê·œ] SHAP ì¢…í•© ë¶„ì„ íƒ­ ---
                                with dpg.tab(label="SHAP ì¢…í•© ë¶„ì„", show=SHAP_AVAILABLE):
                                    _create_shap_dashboard_tab_ui()

        # --- í•˜ë‹¨ ë¡œê·¸ íŒ¨ë„ ---
        dpg.add_separator()
        with dpg.group():
            dpg.add_text("ì§„í–‰ ìƒí™© ë° ë¡œê·¸", color=(100, 200, 255)); dpg.add_progress_bar(tag=TAG_S11_PROGRESS_BAR, default_value=0.0, width=-1)
            with dpg.child_window(height=150, tag=TAG_S11_LOG_WINDOW, border=True):
                dpg.add_input_text(default_value="AutoGluon í›ˆë ¨ì„ ì‹œì‘í•˜ì„¸ìš”.", tag=TAG_S11_LOG_TEXT, multiline=True, readonly=True, width=-1, height=-1)

# --- [ì‹ ê·œ] SHAP ì¢…í•© ë¶„ì„ íƒ­ UI ìƒì„± í•¨ìˆ˜ ---
def _create_shap_dashboard_tab_ui():
    dpg.add_text("SHAP(SHapley Additive exPlanations) ë¶„ì„ì€ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì„¤ëª…í•˜ëŠ” ê°•ë ¥í•œ ê¸°ë²•ì…ë‹ˆë‹¤.", wrap=600)
    dpg.add_separator()
    
    with dpg.group(horizontal=True):
        dpg.add_text("ë¶„ì„ ìƒ˜í”Œ ìˆ˜:")
        dpg.add_input_int(tag="s11_shap_sample_size_input_dashboard", default_value=500, min_value=10, max_value=500, width=120)
        dpg.add_text("(ì£¼ì˜: ê°’ì´ í¬ë©´ ë¶„ì„ ì‹œê°„ì´ ë§¤ìš° ê¸¸ì–´ì§‘ë‹ˆë‹¤)", color=(255, 180, 0))

    dpg.add_button(label="ğŸ“Š SHAP ì¢…í•© ë¶„ì„ ì‹¤í–‰", callback=_run_comprehensive_shap_analysis_callback, height=30)
    dpg.add_separator()
    
    with dpg.child_window(tag=TAG_S11_SHAP_DASHBOARD_WINDOW, border=True, height=-1):
        dpg.add_text("ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ ëŒ€ì‹œë³´ë“œê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.", tag=TAG_S11_SHAP_DASHBOARD_PLACEHOLDER)


def _create_inference_tab_ui():
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    dpg.add_text("í•™ìŠµëœ AutoGluon ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.", wrap=500); dpg.add_separator()
    dpg.add_button(label="ğŸ“‚ ì €ì¥ëœ ëª¨ë¸ í´ë” ë¶ˆëŸ¬ì˜¤ê¸°", callback=lambda: dpg.show_item(TAG_S11_INFERENCE_MODEL_DIALOG)); dpg.add_text("ë¶ˆëŸ¬ì˜¨ ëª¨ë¸: ì—†ìŒ", tag="s11_inference_model_path")
    dpg.add_separator()
    dpg.add_button(label="ğŸ“„ ì˜ˆì¸¡í•  ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (.csv/.parquet)", callback=lambda: dpg.show_item(TAG_S11_INFERENCE_DATA_DIALOG)); dpg.add_text("ì˜ˆì¸¡í•  ë°ì´í„°: ì—†ìŒ", tag="s11_inference_data_path")
    dpg.add_table(tag="s11_inference_data_preview", header_row=True, height=150)
    dpg.add_separator()
    dpg.add_button(label="ì‹¤í–‰", width=-1, callback=_run_inference, height=30, tag="s11_run_inference_button", enabled=False)
    dpg.add_separator(); dpg.add_text("ì˜ˆì¸¡ ê²°ê³¼")
    with dpg.group(horizontal=True):
        dpg.add_text("", tag="s11_inference_result_count")
        dpg.add_button(label="ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", show=False, tag="s11_inference_download_button", callback=_download_inference_result)
    dpg.add_table(tag="s11_inference_result_table", header_row=True, height=200, resizable=True)


# --- ì½œë°± í•¨ìˆ˜ë“¤ ---

def _on_df_or_target_selected(sender, app_data, user_data):
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    df_name, target_name = dpg.get_value(TAG_S11_DF_SELECTOR), dpg.get_value(TAG_S11_TARGET_SELECTOR)
    all_dfs = _module_main_callbacks.get('get_all_available_dfs', lambda: {})()
    if not df_name or df_name not in all_dfs: return
    df = all_dfs[df_name]
    if sender == TAG_S11_DF_SELECTOR:
        cols = [""] + df.columns.tolist()
        dpg.configure_item(TAG_S11_TARGET_SELECTOR, items=cols); dpg.set_value(TAG_S11_TARGET_SELECTOR, "")
    if target_name and target_name in df.columns:
        y = df[target_name]
        task_type = "Regression" if pd.api.types.is_numeric_dtype(y) and y.nunique() >= 25 else "Classification"
        dpg.set_value(TAG_S11_TASK_TYPE_TEXT, f"{task_type}")
    else:
        dpg.set_value(TAG_S11_TASK_TYPE_TEXT, "(íƒ€ê²Ÿ ì„ íƒ)")

def _start_autogluon_fit_callback():
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    global _leaderboard_results, _current_predictor, _current_predictor_path
    df_name = dpg.get_value(TAG_S11_DF_SELECTOR)
    target_name = dpg.get_value(TAG_S11_TARGET_SELECTOR)
    if not df_name or not target_name: _util_funcs['_show_simple_modal_message']("ì„¤ì • ì˜¤ë¥˜", "ë°ì´í„° ì†ŒìŠ¤ì™€ íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”."); return
    preset = dpg.get_value(TAG_S11_PRESET_SELECTOR)
    time_limit = dpg.get_value(TAG_S11_TIME_LIMIT_INPUT)
    df = _module_main_callbacks.get('get_all_available_dfs')().get(df_name)
    if df is None: _util_funcs['_show_simple_modal_message']("ì˜¤ë¥˜", "ì„ íƒëœ ë°ì´í„°í”„ë ˆì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return
    _leaderboard_results.clear()
    _current_predictor, _current_predictor_path = None, None
    _update_leaderboard_display()
    dpg.configure_item(TAG_S11_DEEP_DIVE_GROUP, show=False)
    if dpg.does_item_exist(TAG_S11_RESULTS_TAB_BAR):
        dpg.set_value(TAG_S11_RESULTS_TAB_BAR, TAG_S11_LEADERBOARD_TAB)
    _start_background_task(_run_autogluon_fit_thread, args=(df.copy(), target_name, preset, time_limit))

def _update_leaderboard_display():
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    table = TAG_S11_LEADERBOARD_TABLE
    if not dpg.is_dearpygui_running() or not dpg.does_item_exist(table): return
    dpg.delete_item(table, children_only=True)
    if not _leaderboard_results:
        dpg.add_table_column(label="ì•Œë¦¼", parent=table)
        with dpg.table_row(parent=table): dpg.add_text("AutoGluon í›ˆë ¨ì„ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return
    headers = list(_leaderboard_results[0].keys())
    display_headers = ['model', 'score_val', 'eval_metric', 'pred_time_val', 'fit_time', 'stack_level']
    final_headers = display_headers + [h for h in headers if h not in display_headers]
    for key in final_headers: 
        if key in _leaderboard_results[0]: dpg.add_table_column(label=key, parent=table)
    dpg.add_table_column(label="ë¶„ì„", parent=table, width=100)
    for res in _leaderboard_results:
        with dpg.table_row(parent=table):
            for key in final_headers:
                 if key in res:
                    val = res[key]
                    s_val = f"{val:.4f}" if isinstance(val, (float, np.number)) else str(val)
                    dpg.add_text(s_val)
            with dpg.table_cell():
                dpg.add_button(label="ìƒì„¸", user_data=res.get("model"), callback=_select_model_for_deep_dive)

def _select_model_for_deep_dive(sender, app_data, user_data_model_name):
    # [ìˆ˜ì •] SHAP ê´€ë ¨ ë¡œì§ ì œê±°, UI ì´ˆê¸°í™” ë¡œì§ ì¶”ê°€
    global _current_deep_dive_model_name
    if not _current_predictor: _log_message("ì˜¤ë¥˜: Predictorê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "ERROR"); return
    _current_deep_dive_model_name = user_data_model_name
    
    dpg.configure_item(TAG_S11_DEEP_DIVE_GROUP, show=True)
    if dpg.does_item_exist(TAG_S11_RESULTS_TAB_BAR): dpg.set_value(TAG_S11_RESULTS_TAB_BAR, TAG_S11_DEEP_DIVE_TAB)
    dpg.set_value("s11_deep_dive_model_name", f"Selected Model: {user_data_model_name}")
    
    perf_table = "s11_deep_dive_perf_table"
    dpg.delete_item(perf_table, children_only=True); dpg.add_table_column(label="Metric", parent=perf_table); dpg.add_table_column(label="Value", parent=perf_table)

    try:
        df_name = dpg.get_value(TAG_S11_DF_SELECTOR)
        all_dfs = _module_main_callbacks.get('get_all_available_dfs', lambda: {})()
        df = all_dfs.get(df_name)
        if df is None: raise ValueError(f"'{df_name}' ë°ì´í„°í”„ë ˆì„ì„ í˜„ì¬ ìƒíƒœì—ì„œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        model_perf = _current_predictor.evaluate(df, model=user_data_model_name)
        for metric, value in model_perf.items():
            with dpg.table_row(parent=perf_table): dpg.add_text(metric); dpg.add_text(f"{value:.4f}")
    except Exception as e:
        with dpg.table_row(parent=perf_table): dpg.add_text("Error"); dpg.add_text(f"ì„±ëŠ¥ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        print(f"ì‹¬ì¸µ ë¶„ì„ ì„±ëŠ¥ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\n{traceback.format_exc()}")

    _log_message(f"'{user_data_model_name}' ëª¨ë¸ì´ ì‹¬ì¸µ ë¶„ì„ ëŒ€ìƒìœ¼ë¡œ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # [ìˆ˜ì •] ì´ì „ ë¶„ì„ ê²°ê³¼(í”Œë¡¯)ë“¤ì„ ì´ˆê¸°í™”
    if dpg.does_item_exist(TAG_S11_PERFORMANCE_PLOT_IMAGE): dpg.delete_item(TAG_S11_PERFORMANCE_PLOT_IMAGE)
    if dpg.does_item_exist("s11_perf_plot_placeholder"): dpg.configure_item("s11_perf_plot_placeholder", show=True)
    
    if dpg.does_item_exist(TAG_S11_SHAP_DASHBOARD_WINDOW):
        dpg.delete_item(TAG_S11_SHAP_DASHBOARD_WINDOW, children_only=True)
        dpg.add_text("ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ ëŒ€ì‹œë³´ë“œê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.", tag=TAG_S11_SHAP_DASHBOARD_PLACEHOLDER, parent=TAG_S11_SHAP_DASHBOARD_WINDOW)

def _run_feature_importance_analysis():
    if not _current_predictor: _util_funcs['_show_simple_modal_message']("ì˜¤ë¥˜", "ë¨¼ì € ëª¨ë¸ì„ í›ˆë ¨ì‹œì¼œì£¼ì„¸ìš”."); return
    if dpg.does_item_exist(TAG_S11_PERFORMANCE_PLOT_IMAGE): dpg.delete_item(TAG_S11_PERFORMANCE_PLOT_IMAGE)
    if dpg.does_item_exist("s11_perf_plot_placeholder"): dpg.configure_item("s11_perf_plot_placeholder", show=True)
    _start_background_task(_run_feature_importance_thread)

def _run_comprehensive_shap_analysis_callback():
    if not _current_predictor or not _current_deep_dive_model_name:
        _util_funcs['_show_simple_modal_message']("ì˜¤ë¥˜", "ë¨¼ì € ë¦¬ë”ë³´ë“œì—ì„œ ë¶„ì„í•  ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”."); return

    # ë¶„ì„ ì‹œì‘ ì‹œ, ëŒ€ì‹œë³´ë“œ ì°½ì„ ë¹„ìš°ê³  "ë¡œë”© ì¤‘" ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
    if dpg.does_item_exist(TAG_S11_SHAP_DASHBOARD_WINDOW):
        dpg.delete_item(TAG_S11_SHAP_DASHBOARD_WINDOW, children_only=True)
        dpg.add_text("SHAP ì¢…í•© ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...", parent=TAG_S11_SHAP_DASHBOARD_WINDOW, color=(255,255,0))

    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ SHAP ë¶„ì„ ìŠ¤ë ˆë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
    _start_background_task(_run_comprehensive_shap_thread)

def _run_comprehensive_shap_thread():
    # ì´ í”„ë¦°íŠ¸ë¬¸ì´ ë¡œê·¸ì— ë³´ì´ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
    print("--- [v3] ë¬¸ì œ ì½”ë“œ ì™„ì „ ì œê±° ë²„ì „ ì‹¤í–‰ í™•ì¸ ---")
    _log_message("--- [v3] ì½”ë“œ ì‹¤í–‰ í™•ì¸ ---", "DEBUG") # GUI ë¡œê·¸ì—ë„ í‘œì‹œ

    try:
        # --- ì¤€ë¹„ ê³¼ì • (ê¸°ì¡´ê³¼ ë™ì¼) ---
        if not _current_predictor or not _current_deep_dive_model_name:
            _results_queue.put({"type": "error", "log": "SHAP: ë¶„ì„í•  ëª¨ë¸ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}); return
        _results_queue.put({"type": "progress", "value": 0.05, "log": "SHAP ì¢…í•© ë¶„ì„ ì‹œì‘: ë°ì´í„° ì¤€ë¹„ ì¤‘..."})
        df_name = dpg.get_value(TAG_S11_DF_SELECTOR)
        all_dfs = _module_main_callbacks.get('get_all_available_dfs', lambda: {})()
        data_for_analysis = all_dfs.get(df_name)
        if data_for_analysis is None: raise ValueError(f"'{df_name}' ë°ì´í„°í”„ë ˆì„ì„ í˜„ì¬ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sample_size = dpg.get_value("s11_shap_sample_size_input_dashboard")
        if len(data_for_analysis) > sample_size:
            _log_message(f"SHAP: ë°ì´í„°ê°€ ë§ì•„ {sample_size}ê°œ í–‰ìœ¼ë¡œ ìƒ˜í”Œë§í•©ë‹ˆë‹¤.", "WARN")
            data_sample = data_for_analysis.sample(n=sample_size, random_state=42)
        else:
            data_sample = data_for_analysis.copy()
        _results_queue.put({"type": "progress", "value": 0.2, "log": "SHAP ê°’ ê³„ì‚° ì¤‘... (ì‹œê°„ ì†Œìš”)"})
        X_sample = data_sample.drop(columns=[_current_predictor.label])

        X_sample_for_plotting = X_sample.copy()

        # --- ì´í•˜ SHAP ê°’ ê³„ì‚° ë° í”Œë¡¯ ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼) ---
        X_sample_numeric = X_sample.copy()
        for col in X_sample_numeric.columns:
            if not pd.api.types.is_numeric_dtype(X_sample_numeric[col]):
                X_sample_numeric[col] = X_sample_numeric[col].astype('category').cat.codes

        if _current_predictor.problem_type in ['binary', 'multiclass']:
            def predict_fn(x):
                df_pred = pd.DataFrame(x, columns=X_sample.columns)
                return _current_predictor.predict_proba(df_pred, model=_current_deep_dive_model_name)
        else:
            def predict_fn(x):
                df_pred = pd.DataFrame(x, columns=X_sample.columns)
                return _current_predictor.predict(df_pred, model=_current_deep_dive_model_name)

        masker = shap.maskers.Partition(X_sample_numeric)
        explainer = shap.Explainer(predict_fn, masker)
        shap_values = explainer(X_sample_numeric)
        shap_values.data = X_sample.values

        shap_values_to_plot = shap_values
        if _current_predictor.problem_type == 'binary':
            try:
                positive_class_index = _current_predictor.class_labels.index(_current_predictor.positive_class)
                shap_values_to_plot = shap_values[..., positive_class_index]
            except (ValueError, AttributeError, IndexError):
                shap_values_to_plot = shap_values[..., 1]

        _results_queue.put({"type": "progress", "value": 0.6, "log": "SHAP ê°’ ê³„ì‚° ì™„ë£Œ. í”Œë¡¯ ìƒì„± ì¤‘..."})

        all_plots_data = []
        plt.style.use('seaborn-v0_8-darkgrid')

        try:
            shap.plots.bar(shap_values_to_plot, show=False)
            fig = plt.gcf(); plt.title('SHAP Global Feature Importance'); plt.tight_layout()
            if texture_info := _util_funcs['plot_to_dpg_texture'](fig):
                all_plots_data.append({'title': 'ì „ì—­ í”¼ì²˜ ì¤‘ìš”ë„ (Bar Plot)', 'texture_info': texture_info})
            plt.close(fig)
        except Exception as e: _log_message(f"SHAP Bar Plot ìƒì„± ì‹¤íŒ¨: {e}", "ERROR")

        try:
            shap.summary_plot(shap_values_to_plot, X_sample_for_plotting, show=False, plot_type="dot")
            fig = plt.gcf(); plt.title('SHAP Summary Plot'); plt.tight_layout()
            # [ìˆ˜ì • 1] í•¨ìˆ˜ ì´ë¦„ì˜ ì˜¤íƒ€ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤. ('plot_to_d_texture' -> 'plot_to_dpg_texture')
            if texture_info := _util_funcs['plot_to_dpg_texture'](fig):
                all_plots_data.append({'title': 'íŠ¹ì„±ë³„ ì˜í–¥ ìš”ì•½ (Summary Plot)', 'texture_info': texture_info})
            plt.close(fig)
        except Exception as e: _log_message(f"SHAP Summary Plot ìƒì„± ì‹¤íŒ¨: {e}", "ERROR")

        try:
            top_feature_indices = np.argsort(np.abs(shap_values_to_plot.values).mean(0))[-4:]
            top_features = X_sample.columns[top_feature_indices]
            for feature in reversed(top_features):
                # [ìˆ˜ì • 2] ê²°ì¸¡ì¹˜ë¡œ ì¸í•œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ interaction_indexë¥¼ 'auto'ì—ì„œ Noneìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
                shap.dependence_plot(feature, shap_values_to_plot.values, X_sample_for_plotting, show=False, interaction_index=None)
                fig = plt.gcf(); plt.title(f'SHAP Dependence Plot for "{feature}"'); plt.tight_layout()
                if texture_info := _util_funcs['plot_to_dpg_texture'](fig):
                    all_plots_data.append({'title': f'ì˜ì¡´ì„± í”Œë¡¯: {feature}', 'texture_info': texture_info})
                plt.close(fig)
        except Exception as e:
            error_detail = f"SHAP Dependence Plot ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
            _log_message(error_detail, "WARN")

        if all_plots_data:
            _results_queue.put({"type": "shap_dashboard_result", "plots": all_plots_data})
        else:
            _results_queue.put({"type": "error", "log": "ìƒì„±ëœ SHAP í”Œë¡¯ì´ ì—†ìŠµë‹ˆë‹¤."})

    except Exception as e:
        error_msg = f"SHAP ì¢…í•© ë¶„ì„ ì˜¤ë¥˜: {str(e)}\n{traceback.format_exc()}"
        _results_queue.put({"type": "error", "log": error_msg})

# --- [ìˆ˜ì •] UI ì—…ë°ì´íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜ ---
def _check_for_updates():
    global _worker_thread, _leaderboard_results, _current_predictor, _current_predictor_path
    try:
        result = _results_queue.get_nowait()
        if result["type"] == "progress": _update_progress(result.get("value", 0), result.get("log", ""))
        elif result["type"] == "error": _log_message(result["log"], "ERROR"); _update_progress(0.0, "ì‘ì—… ì‹¤íŒ¨.")
        elif result["type"] == "autogluon_result":
            _leaderboard_results = result.get("leaderboard", [])
            _current_predictor_path = result.get("predictor_path")
            if _current_predictor_path: _current_predictor = TabularPredictor.load(_current_predictor_path)
            _update_leaderboard_display(); _update_progress(1.0, "AutoML í›ˆë ¨ ì™„ë£Œ."); time.sleep(1); _update_progress(0.0)
        
        # [ìˆ˜ì •] í”¼ì²˜ ì¤‘ìš”ë„ í”Œë¡¯ ê²°ê³¼ ì²˜ë¦¬
        elif result["type"] == "performance_plot_result":
            if dpg.does_item_exist(TAG_S11_PERFORMANCE_PLOT_IMAGE): dpg.delete_item(TAG_S11_PERFORMANCE_PLOT_IMAGE)
            if dpg.does_item_exist("s11_perf_plot_placeholder"): dpg.configure_item("s11_perf_plot_placeholder", show=False)
            dpg.add_image(result["texture_tag"], width=result["width"], height=result["height"], parent=TAG_S11_PERFORMANCE_PLOT_WINDOW, tag=TAG_S11_PERFORMANCE_PLOT_IMAGE)
            _update_progress(1.0, "í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ ì™„ë£Œ."); time.sleep(1); _update_progress(0.0)
            _texture_tags.append(result["texture_tag"])

        # --- [ì‹ ê·œ] SHAP ëŒ€ì‹œë³´ë“œ ê²°ê³¼ ì²˜ë¦¬ ---
        elif result["type"] == "shap_dashboard_result":
            plots_data = result.get("plots", [])
            dpg.delete_item(TAG_S11_SHAP_DASHBOARD_WINDOW, children_only=True)
            if not plots_data:
                dpg.add_text("ì˜¤ë¥˜: ìƒì„±ëœ SHAP í”Œë¡¯ì´ ì—†ìŠµë‹ˆë‹¤.", parent=TAG_S11_SHAP_DASHBOARD_WINDOW, color=(255,0,0))
                return

            new_texture_tags = []
            for plot in plots_data:
                title = plot['title']
                texture_tag, width, height, _ = plot['texture_info']
                new_texture_tags.append(texture_tag)
                dpg.add_text(title, parent=TAG_S11_SHAP_DASHBOARD_WINDOW, color=(100, 200, 255))
                dpg.add_image(texture_tag, width=width, height=height, parent=TAG_S11_SHAP_DASHBOARD_WINDOW)
                dpg.add_separator(parent=TAG_S11_SHAP_DASHBOARD_WINDOW)
            
            _texture_tags.extend(new_texture_tags)
            _update_progress(1.0, "SHAP ì¢…í•© ë¶„ì„ ì™„ë£Œ."); time.sleep(1); _update_progress(0.0)

        _results_queue.task_done()
    except queue.Empty: pass
    except Exception as e: print(f"ì—…ë°ì´íŠ¸ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\n{traceback.format_exc()}")
    if _worker_thread and not _worker_thread.is_alive(): _worker_thread = None


def _update_progress(value: float, message: str = ""):
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    if not dpg.is_dearpygui_running(): return
    if dpg.does_item_exist(TAG_S11_PROGRESS_BAR): dpg.set_value(TAG_S11_PROGRESS_BAR, value)
    if message: _log_message(message)

def update_ui():
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    if not _module_main_callbacks or not dpg.is_dearpygui_running(): return
    all_dfs = _module_main_callbacks.get('get_all_available_dfs', lambda: {})()
    if dpg.does_item_exist(TAG_S11_DF_SELECTOR):
        df_names = [""] + list(all_dfs.keys())
        dpg.configure_item(TAG_S11_DF_SELECTOR, items=df_names)

def reset_state():
    # [ìˆ˜ì •] ìƒíƒœ ì´ˆê¸°í™” ì‹œ SHAP ëŒ€ì‹œë³´ë“œë„ ì´ˆê¸°í™”
    global _worker_thread, _leaderboard_results, _texture_tags, _current_deep_dive_model_name
    global _current_predictor, _current_predictor_path, _inference_predictor, _inference_df, _inference_result_df
    
    if _worker_thread and _worker_thread.is_alive(): return
    
    _leaderboard_results.clear(); _current_deep_dive_model_name = None
    _current_predictor, _current_predictor_path = None, None
    _inference_predictor, _inference_df, _inference_result_df = None, None, None

    for tag in _texture_tags:
        if dpg.does_item_exist(tag): dpg.delete_item(tag)
    _texture_tags.clear()

    if os.path.exists("autogluon_models"):
        try: shutil.rmtree("autogluon_models"); _log_message("ì´ì „ AutoGluon ëª¨ë¸ ê²°ê³¼ í´ë”ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.", "INFO")
        except Exception as e: _log_message(f"ëª¨ë¸ í´ë” ì‚­ì œ ì‹¤íŒ¨: {e}", "ERROR")

    if dpg.is_dearpygui_running():
        _update_leaderboard_display()
        dpg.configure_item(TAG_S11_DEEP_DIVE_GROUP, show=False)
        # [ìˆ˜ì •] ëª¨ë“  í”Œë¡¯ ì˜ì—­ ì´ˆê¸°í™”
        if dpg.does_item_exist(TAG_S11_PERFORMANCE_PLOT_IMAGE): dpg.delete_item(TAG_S11_PERFORMANCE_PLOT_IMAGE)
        if dpg.does_item_exist("s11_perf_plot_placeholder"): dpg.configure_item("s11_perf_plot_placeholder", show=True)
        if dpg.does_item_exist(TAG_S11_SHAP_DASHBOARD_WINDOW):
            dpg.delete_item(TAG_S11_SHAP_DASHBOARD_WINDOW, children_only=True)
            dpg.add_text("ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ ëŒ€ì‹œë³´ë“œê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.", tag=TAG_S11_SHAP_DASHBOARD_PLACEHOLDER, parent=TAG_S11_SHAP_DASHBOARD_WINDOW)

        # ì¶”ë¡  íƒ­ ì´ˆê¸°í™” (ê¸°ì¡´ê³¼ ë™ì¼)
        dpg.set_value("s11_inference_model_path", "ë¶ˆëŸ¬ì˜¨ ëª¨ë¸: ì—†ìŒ"); dpg.set_value("s11_inference_data_path", "ì˜ˆì¸¡í•  ë°ì´í„°: ì—†ìŒ")
        if dpg.does_item_exist("s11_inference_data_preview"): dpg.delete_item("s11_inference_data_preview", children_only=True)
        if dpg.does_item_exist("s11_inference_result_table"): dpg.delete_item("s11_inference_result_table", children_only=True)
        dpg.configure_item("s11_inference_download_button", show=False)
        _check_inference_readiness()
        update_ui()
    _log_message("ML ëª¨ë¸ë§ ìƒíƒœê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.", "INFO")

# --- Inference Tab Functions (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼) ---
def _check_inference_readiness():
    ready = _inference_predictor is not None and _inference_df is not None
    if dpg.does_item_exist("s11_run_inference_button"): dpg.configure_item("s11_run_inference_button", enabled=ready)

def _on_model_dir_selected(sender, app_data):
    global _inference_predictor
    try:
        dir_path = app_data['file_path_name']
        _inference_predictor = TabularPredictor.load(dir_path)
        dpg.set_value("s11_inference_model_path", f"ë¶ˆëŸ¬ì˜¨ ëª¨ë¸: {os.path.basename(dir_path)}")
        _log_message(f"ì¶”ë¡  ëª¨ë¸ '{os.path.basename(dir_path)}' ë¡œë“œ ì™„ë£Œ."); _check_inference_readiness()
    except Exception as e:
        _inference_predictor = None; _util_funcs['_show_simple_modal_message']("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨", f"AutoGluon ëª¨ë¸ í´ë” ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\n{e}")
        dpg.set_value("s11_inference_model_path", "ë¶ˆëŸ¬ì˜¨ ëª¨ë¸: ì—†ìŒ (ë¡œë“œ ì‹¤íŒ¨)"); _check_inference_readiness()

def _on_inference_data_selected(sender, app_data):
    global _inference_df
    try:
        file_path = app_data['file_path_name']
        if file_path.endswith('.csv'): _inference_df = pd.read_csv(file_path)
        elif file_path.endswith('.parquet'): _inference_df = pd.read_parquet(file_path)
        else: raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
        if _inference_predictor and _inference_predictor.label in _inference_df.columns:
             _inference_df = _inference_df.drop(columns=[_inference_predictor.label])
             _log_message(f"ì¶”ë¡  ë°ì´í„°ì—ì„œ íƒ€ê²Ÿ ë³€ìˆ˜ '{_inference_predictor.label}'ë¥¼ ìë™ìœ¼ë¡œ ì œê±°í–ˆìŠµë‹ˆë‹¤.", "WARN")
        dpg.set_value("s11_inference_data_path", f"ì˜ˆì¸¡í•  ë°ì´í„°: {os.path.basename(file_path)} ({_inference_df.shape})")
        if _util_funcs and 'create_table_with_large_data_preview' in _util_funcs: _util_funcs['create_table_with_large_data_preview']("s11_inference_data_preview", _inference_df)
        _log_message(f"ì¶”ë¡  ë°ì´í„° '{os.path.basename(file_path)}' ë¡œë“œ ì™„ë£Œ."); _check_inference_readiness()
    except Exception as e:
        _inference_df = None; _util_funcs['_show_simple_modal_message']("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨", f"ë°ì´í„° íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\n{e}")
        dpg.set_value("s11_inference_data_path", "ì˜ˆì¸¡í•  ë°ì´í„°: ì—†ìŒ (ë¡œë“œ ì‹¤íŒ¨)"); _check_inference_readiness()

def _run_inference():
    global _inference_result_df
    if _inference_predictor is None or _inference_df is None: _util_funcs['_show_simple_modal_message']("ì˜¤ë¥˜", "ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ëª¨ë‘ ë¶ˆëŸ¬ì™€ì•¼ í•©ë‹ˆë‹¤."); return
    try:
        _log_message("ì¶”ë¡  ì‹œì‘...")
        predictions = _inference_predictor.predict(_inference_df)
        result_df = _inference_df.copy(); result_df['prediction'] = predictions
        if _inference_predictor.problem_type != 'regression':
            pred_probas = _inference_predictor.predict_proba(_inference_df)
            for col in pred_probas.columns: result_df[f'proba_{col}'] = pred_probas[col]
        _inference_result_df = result_df
        if _util_funcs and 'create_table_with_large_data_preview' in _util_funcs: _util_funcs['create_table_with_large_data_preview']("s11_inference_result_table", _inference_result_df)
        dpg.set_value("s11_inference_result_count", f"ì´ {len(_inference_result_df)}ê°œ í–‰ ì˜ˆì¸¡ ì™„ë£Œ"); dpg.configure_item("s11_inference_download_button", show=True)
        _log_message("ì¶”ë¡  ì™„ë£Œ.")
    except Exception as e:
        _util_funcs['_show_simple_modal_message']("ì¶”ë¡  ì˜¤ë¥˜", f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\n{e}\n\nì…ë ¥ ë°ì´í„°ì˜ ì»¬ëŸ¼ê³¼ í˜•ì‹ì´ ëª¨ë¸ í›ˆë ¨ ì‹œì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        _log_message(f"ì¶”ë¡  ì˜¤ë¥˜: {e}", "ERROR")

def _on_save_inference_result_selected(sender, app_data):
    try:
        file_path = app_data['file_path_name']
        if _inference_result_df is not None:
            _inference_result_df.to_csv(file_path, index=False)
            _util_funcs['_show_simple_modal_message']("ì €ì¥ ì™„ë£Œ", f"ì¶”ë¡  ê²°ê³¼ê°€ ë‹¤ìŒ ê²½ë¡œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\n{file_path}")
            _log_message(f"ì¶”ë¡  ê²°ê³¼ê°€ '{file_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e: _util_funcs['_show_simple_modal_message']("ì €ì¥ ì‹¤íŒ¨", f"ì¶”ë¡  ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\n{e}")

def _download_inference_result():
    if _inference_result_df is None: _util_funcs['_show_simple_modal_message']("ì˜¤ë¥˜", "ë‹¤ìš´ë¡œë“œí•  ì¶”ë¡  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."); return
    dpg.show_item(TAG_S11_INFERENCE_SAVE_DIALOG)