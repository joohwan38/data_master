# step_11_ml_modeling.py - 1ë‹¨ê³„ êµ¬í˜„ (ë¹„ë™ê¸° ì²˜ë¦¬, AutoML, SHAP)

"""
Step 11 ML Modeling & AI í†µí•© ëª¨ë“ˆ (Phase 1 Implementation)

ê°•í™”ëœ ê¸°ëŠ¥:
- ë¹„ë™ê¸° ì²˜ë¦¬:ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®å­¦ç¿’ãƒ»åˆ†æã«ã‚ˆã‚‹UIãƒ•ãƒªãƒ¼ã‚ºé˜²æ­¢
- AutoML: LightAutoMLì„ ì´ìš©í•œ ëª¨ë¸ ì„ íƒ, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ìë™í™”
- SHAP: ëª¨ë¸ ì˜ˆì¸¡ì— ëŒ€í•œ í”¼ì²˜ ì˜í–¥ë„ ë° ë°©í–¥ì„± ë¶„ì„
- ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§: í•™ìŠµ ê³¼ì • ë¡œê·¸ ë° ì§„í–‰ë¥  í‘œì‹œ
"""

import dearpygui.dearpygui as dpg
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
import traceback
import datetime
import pickle
import json
import sys
import uuid
from dataclasses import dataclass, asdict
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import (accuracy_score, precision_recall_fscore_support, confusion_matrix,
                           mean_squared_error, r2_score, mean_absolute_error, roc_curve, auc)
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import threading
import queue
import time
import re

# --- ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„¤ì¹˜ í•„ìš”) ---
from lightautoml.automl.presets.tabular_presets import TabularAutoML
from lightautoml.addons.tabular_interpretation import SSWARM
from lightautoml.tasks import Task
import shap
# from lightautoml.explain.shap import SSWARM

warnings.filterwarnings('ignore')

# --- Classification/Regression Models (ê¸°ì¡´ê³¼ ë™ì¼) ---
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
# ... (ê¸°íƒ€ ëª¨ë¸ë“¤ì€ ê°„ê²°ì„±ì„ ìœ„í•´ ìƒëµ)

# --- DPG Tags ---
TAG_S11_GROUP = "step11_ml_modeling_group"
TAG_S11_UPPER_VIZ_WINDOW = "step11_upper_viz_window"
TAG_S11_LOWER_CONTROL_PANEL = "step11_lower_control_panel"
TAG_S11_VIZ_TAB_BAR = "step11_viz_tab_bar"

TAG_S11_EXPERIMENT_TAB = "step11_experiment_tab"
TAG_S11_MONITORING_TAB = "step11_monitoring_tab"
# --- [1ë‹¨ê³„ ì¶”ê°€] ---
TAG_S11_AUTOML_TAB = "step11_automl_tab" 
TAG_S11_AUTOML_CONTROLS_GROUP = "s11_automl_controls_group"
TAG_S11_AUTOML_RESULTS_GROUP = "s11_automl_results_group"
TAG_S11_AUTOML_RUN_BUTTON = "s11_automl_run_button"

TAG_S11_PROGRESS_BAR = "step11_progress_bar"
TAG_S11_LOG_WINDOW = "step11_log_window"
TAG_S11_EXPERIMENT_TABLE = "step11_experiment_table"
TAG_S11_DF_SELECTOR = "step11_df_selector"

# --- ML_ALGORITHMS (ê¸°ì¡´ê³¼ ë™ì¼) ---
ML_ALGORITHMS = {
    "Classification": {
        "Logistic Regression": {"class": LogisticRegression, "params": {}},
        "Random Forest": {"class": RandomForestClassifier, "params": {"n_estimators": 100}},
    },
    "Regression": {
        "Linear Regression": {"class": LinearRegression, "params": {}},
        "Random Forest": {"class": RandomForestRegressor, "params": {"n_estimators": 100}},
    },
    "Clustering": {} # ê°„ê²°ì„± ìœ„í•´ ìƒëµ
}

# --- Module State ë³€ìˆ˜ ---
_module_main_callbacks: Optional[Dict] = None
_util_funcs: Optional[Dict[str, Any]] = None
_experiments_history: List['ExperimentResult'] = []
_texture_tags: List[str] = []
# --- [1ë‹¨ê³„ ì¶”ê°€] ë¹„ë™ê¸° ì²˜ë¦¬ ê´€ë ¨ ë³€ìˆ˜ ---
_results_queue = queue.Queue()
_worker_thread: Optional[threading.Thread] = None
_detected_task_type: str = "" 


@dataclass
class ExperimentResult:
    """ì‹¤í—˜ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤ (ê¸°ì¡´ê³¼ ë™ì¼)"""
    id: str
    timestamp: datetime.datetime
    model_name: str
    model_type: str
    algorithm: str
    parameters: Dict[str, Any]
    features: List[str]
    target: str
    metrics: Dict[str, Any]
    training_time: float
    model_object: Any # í•™ìŠµëœ ëª¨ë¸ ê°ì²´ ì €ì¥
    dataframe_name: str # ì–´ë–¤ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í•™ìŠµí–ˆëŠ”ì§€ ê¸°ë¡
    
    def to_dict(self):
        d = asdict(self)
        d.pop('model_object', None)
        return d
    
def _update_automl_target_combo(df_name: str):
    """(ìµœì¢… ìˆ˜ì •) 'ë¶„ì„ ì œì™¸' ì»¬ëŸ¼ì„ UI ëª©ë¡ì—ì„œ ì œê±°"""
    all_dfs = _module_main_callbacks.get('get_all_available_dfs', lambda: {})()
    if not df_name or df_name not in all_dfs:
        if dpg.does_item_exist("s11_automl_target_combo"): dpg.configure_item("s11_automl_target_combo", items=[])
        if dpg.does_item_exist("s11_automl_detected_task"): dpg.set_value("s11_automl_detected_task", "(select source)")
        return

    df = all_dfs[df_name]
    
    # --- ì•„ë˜ ë¡œì§ ì¶”ê°€ ---
    # 1. Step 1ì˜ íƒ€ì… ì„¤ì •ì„ ê°€ì ¸ì™€ 'ë¶„ì„ ì œì™¸' ëª©ë¡ ìƒì„±
    step1_type_selections = _module_main_callbacks.get('get_column_analysis_types', lambda: {})()
    cols_to_exclude = {col for col, type_val in step1_type_selections.items() if type_val == "ë¶„ì„ì—ì„œ ì œì™¸ (Exclude)"}
    
    # 2. ì „ì²´ ì»¬ëŸ¼ ëª©ë¡ì—ì„œ ì œì™¸í•  ì»¬ëŸ¼ì„ ëº€ ìµœì¢… í›„ë³´ ëª©ë¡ ìƒì„±
    candidate_cols = [col for col in df.columns if col not in cols_to_exclude]
    # --- ì—¬ê¸°ê¹Œì§€ ì¶”ê°€ ---
    
    combo_tag = "s11_automl_target_combo"
    if not dpg.does_item_exist(combo_tag): return
        
    # í›„ë³´ ëª©ë¡ìœ¼ë¡œ ì½¤ë³´ë°•ìŠ¤ ì•„ì´í…œ ì„¤ì •
    dpg.configure_item(combo_tag, items=candidate_cols)
    
    final_target = ""
    if _module_main_callbacks and 'get_selected_target_variable' in _module_main_callbacks:
        global_target = _module_main_callbacks['get_selected_target_variable']()
        # ì „ì—­ íƒ€ê²Ÿì´ í›„ë³´ ëª©ë¡ì— ìˆì„ ê²½ìš°ì—ë§Œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
        if global_target and global_target in candidate_cols:
            final_target = global_target
        elif candidate_cols:
            final_target = candidate_cols[0]
            
    if final_target:
        dpg.set_value(combo_tag, final_target)
        _detect_and_update_task_type(df_name, final_target)
    else:
        # ì„ íƒí•  ìˆ˜ ìˆëŠ” íƒ€ê²Ÿì´ í•˜ë‚˜ë„ ì—†ëŠ” ê²½ìš°
        dpg.set_value(combo_tag, "")
        _detect_and_update_task_type(df_name, "")

def _detect_and_update_task_type(df_name: str, target_name: str):
    """(ì‹ ì„¤) ì„ íƒëœ Target ë³€ìˆ˜ë¥¼ ë¶„ì„í•˜ì—¬ Task ìœ í˜•ì„ ê²°ì •í•˜ê³  UIë¥¼ ì—…ë°ì´íŠ¸"""
    global _detected_task_type

    # ìµœì‹  DF ëª©ë¡ì„ ì§ì ‘ ê°€ì ¸ì˜´
    all_dfs = _module_main_callbacks['get_all_available_dfs']()
    if not df_name or not target_name or df_name not in all_dfs:
        _detected_task_type = ""
        if dpg.does_item_exist("s11_automl_detected_task"):
            dpg.set_value("s11_automl_detected_task", "(error)")
        return

    df = all_dfs[df_name]
    if target_name not in df.columns:
        _detected_task_type = ""
        return

    target_series = df[target_name]
    nunique = target_series.nunique()
    dtype_kind = target_series.dtype.kind
    
    task = 'reg'  # ê¸°ë³¸ê°’ì€ íšŒê·€(reg)
    
    # ë°ì´í„° íƒ€ì…ì´ ë¬¸ìì—´/ì¹´í…Œê³ ë¦¬ì´ê±°ë‚˜, ì •ìˆ˜í˜•ì¸ë° ê³ ìœ ê°’ì´ 20ê°œ ë¯¸ë§Œì¸ ê²½ìš°
    if dtype_kind in 'Ocb' or (dtype_kind == 'i' and nunique < 20):
        if nunique == 2:
            task = 'binary'
        else:
            task = 'multiclass'
    
    _detected_task_type = task
    if dpg.does_item_exist("s11_automl_detected_task"):
        dpg.set_value("s11_automl_detected_task", task)

def _on_automl_target_changed(sender, target_name, user_data):
    """(ì‹ ì„¤) AutoML íƒ€ê²Ÿ ì½¤ë³´ë°•ìŠ¤ ë³€ê²½ ì‹œ ì½œë°±"""
    df_name = dpg.get_value(TAG_S11_DF_SELECTOR)
    _detect_and_update_task_type(df_name, target_name)

# --- [1ë‹¨ê³„] ë¹„ë™ê¸° ì‘ì—… ë˜í¼ ---
def _start_background_task(target_func, args):
    """ì‘ì—… ìŠ¤ë ˆë“œë¥¼ ì‹œì‘í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    global _worker_thread
    if _worker_thread and _worker_thread.is_alive():
        _log_message("ERROR: A task is already running.", "ERROR")
        if _util_funcs: _util_funcs['_show_simple_modal_message']("Task Busy", "A previous task is still running. Please wait.")
        return
    _worker_thread = threading.Thread(target=target_func, args=args, daemon=True)
    _worker_thread.start()
    _update_progress(0.0, "Task started in background...")


def _run_automl_in_thread(df: pd.DataFrame, target: str, task_type: str, time_budget: int):
    """(ìµœì¢… ìˆ˜ì •) 'ë¶„ì„ ì œì™¸' ì»¬ëŸ¼ ì œê±° ë° 'ì—­í• ' ëª…ì‹œì  ì§€ì •ì„ í†µí•´ AutoML ì‹¤í–‰"""
    start_time = time.time()
    try:
        if TabularAutoML is None:
            raise ImportError("LightAutoML is not installed. Please run 'pip install lightautoml'.")

        _results_queue.put({"type": "progress", "value": 0.1, "log": "Preparing data for AutoML..."})

        step1_type_selections = _module_main_callbacks.get('get_column_analysis_types', lambda: {})()
        cols_to_exclude = [col for col, type_val in step1_type_selections.items() if type_val == "ë¶„ì„ì—ì„œ ì œì™¸ (Exclude)"]
        
        if target in cols_to_exclude:
            cols_to_exclude.remove(target)
            
        if cols_to_exclude:
            df = df.drop(columns=cols_to_exclude, errors='ignore')
            _results_queue.put({"type": "progress", "value": 0.15, "log": f"Excluded {len(cols_to_exclude)} columns from analysis."})

        # --- ì•„ë˜ ë¡œì§ ì¶”ê°€ ---
        # LightAutoML í˜¸í™˜ì„±ì„ ìœ„í•´ 'category' íƒ€ì…ì„ 'object' íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        for col in df.columns:
            if pd.api.types.is_categorical_dtype(df[col].dtype):
                df[col] = df[col].astype('object')
        # --- ì—¬ê¸°ê¹Œì§€ ì¶”ê°€ ---

        original_columns = df.columns.tolist()
        new_columns = [re.sub(r'[^A-Za-z0-9_]+', '_', col) for col in original_columns]
        df.columns = new_columns
        try:
            target_index = original_columns.index(target)
            target = new_columns[target_index]
        except ValueError:
            _results_queue.put({"type": "error", "log": f"Target column '{target}' not found."})
            return

        task = Task(task_type)
        categorical_features = []
        numeric_features = []
        
        for col in df.columns:
            if col == target:
                continue
            
            if df[col].dtype.name in ['object', 'category'] or df[col].nunique() < 25:
                categorical_features.append(col)
            else:
                numeric_features.append(col)

        roles = {
            'target': target,
            'category': categorical_features,
            'numeric': numeric_features,
        }
        
        _results_queue.put({"type": "progress", "value": 0.2, "log": f"Roles defined. Categorical: {len(categorical_features)}, Numeric: {len(numeric_features)}"})
        
        automl = TabularAutoML(task=task, timeout=time_budget, cpu_limit=1,
                               general_params={"use_algos": [["lgb"]]}) 

        _results_queue.put({"type": "progress", "value": 0.3, "log": "Fitting AutoML model..."})
        oof_predictions = automl.fit_predict(df, roles=roles, verbose=1)
        
        # (ì´í•˜ ì½”ë“œ ë™ì¼)
        training_time = time.time() - start_time
        _results_queue.put({"type": "progress", "value": 0.9, "log": "AutoML fitting complete. Generating report..."})
        
        feature_scores_df = automl.get_feature_scores()
        if not feature_scores_df.empty:
            feature_scores_df['Feature'] = feature_scores_df['Feature'].map(lambda x: original_columns[new_columns.index(x)] if x in new_columns else x)
            feature_scores = feature_scores_df.set_index('Feature')['Importance'].to_dict()
        else:
            feature_scores = {}

        report = {
            "model_name": f"AutoML_{original_columns[new_columns.index(target)]}",
            "algorithm": "LightAutoML",
            "model_type": "Classification" if task_type in ['binary', 'multiclass'] else "Regression",
            "target": original_columns[new_columns.index(target)],
            "training_time": training_time,
            "feature_scores": feature_scores,
            "model_object": automl,
        }
        _results_queue.put({"type": "automl_result", "data": report})

    except Exception as e:
        _results_queue.put({"type": "error", "log": f"AutoML Error: {e}"})
        traceback.print_exc()

# --- [1ë‹¨ê³„] SHAP ë¶„ì„ ë¡œì§ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰) ---
def _run_shap_in_thread(experiment: ExperimentResult, df: pd.DataFrame):
    """(ë””ë²„ê¹… ë²„ì „) ë°ì´í„° ì²˜ë¦¬ ë‹¨ê³„ë³„ë¡œ ë¡œê·¸ë¥¼ ì¶”ê°€í•˜ì—¬ ë¬¸ì œ ì›ì¸ ì¶”ì """
    try:
        if SSWARM is None:
            raise ImportError("SHAP or LightAutoML's SSWARM is not installed.")

        _results_queue.put({"type": "progress", "value": 0.05, "log": "--- Starting SHAP Analysis (Debug Mode) ---"})
        
        model = experiment.model_object
        features = experiment.features
        
        # --- ë””ë²„ê¹… 1: ìµœì´ˆ ë°ì´í„° ìƒíƒœ ---
        try:
            X = df[features].copy()
            _results_queue.put({"type": "progress", "log": f"[DEBUG 1] Initial X shape: {X.shape}, Columns: {X.columns.tolist()}"})
        except Exception as e:
            _results_queue.put({"type": "error", "log": f"[DEBUG 1 FAILED] Could not select features. Error: {e}"})
            return

        # ì»¬ëŸ¼ ì´ë¦„ ì •ë¦¬
        original_feature_names = X.columns.tolist()
        new_columns = [re.sub(r'[^A-Za-z0-9_]+', '_', col) for col in original_feature_names]
        X.columns = new_columns
        # --- ë””ë²„ê¹… 2: ì»¬ëŸ¼ ì´ë¦„ ì •ë¦¬ í›„ ---
        _results_queue.put({"type": "progress", "log": f"[DEBUG 2] After name sanitization, X shape: {X.shape}"})

        # íƒ€ì… ë³€í™˜
        for col in X.columns:
            if pd.api.types.is_categorical_dtype(X[col].dtype):
                X[col] = X[col].astype('object')
        # --- ë””ë²„ê¹… 3: íƒ€ì… ë³€í™˜ í›„ ---
        _results_queue.put({"type": "progress", "log": f"[DEBUG 3] After type conversion, X shape: {X.shape}"})

        # ë¼ë²¨ ì¸ì½”ë”©
        for col in X.select_dtypes(include=['object']).columns:
            le = LabelEncoder()
            X[col] = pd.Series(le.fit_transform(X[col].astype(str)), index=X.index)
        # --- ë””ë²„ê¹… 4: ë¼ë²¨ ì¸ì½”ë”© í›„ ---
        _results_queue.put({"type": "progress", "log": f"[DEBUG 4] After LabelEncoding, X shape: {X.shape}, Dtypes: {X.dtypes.to_dict()}"})

        # --- ë””ë²„ê¹… 5: ìµœì¢… ë°ì´í„° í™•ì¸ ---
        _results_queue.put({"type": "progress", "value": 0.3, "log": f"[DEBUG 5] Final data check before SHAP. Shape: {X.shape}"})

        # SSWARM ì•Œê³ ë¦¬ì¦˜ì„ ìœ„í•œ í”¼ì²˜ ê°œìˆ˜ ë°©ì–´ ì½”ë“œ (ì—¬ì „íˆ ìœ íš¨)
        if X.shape[1] < 4:
            message = f"SHAP analysis skipped: The final feature count is less than 4 ({X.shape[1]}). Check debug logs for data loss."
            _results_queue.put({"type": "error", "log": message})
            return

        explainer = SSWARM(model)
        _results_queue.put({"type": "progress", "value": 0.6, "log": "Calculating SHAP values..."})
        shap_values = explainer.shap_values(X)
        _results_queue.put({"type": "progress", "value": 0.9, "log": "Generating SHAP summary plot..."})
        
        fig, ax = plt.subplots()
        shap_values_to_plot = shap_values[1] if isinstance(shap_values, list) and len(shap_values) == 2 else shap_values

        # --- ì•„ë˜ ë¡œì§ ì¶”ê°€/ìˆ˜ì • ---

        # 1. SSWARMì´ ì‹¤ì œë¡œ ì‚¬ìš©í•œ í”¼ì²˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (sanitizedëœ ì´ë¦„)
        used_features_sanitized = explainer.used_feats
        
        # 2. í”Œë¡¯ì— ì‚¬ìš©í•  ë°ì´í„°ë„ ì‹¤ì œ ì‚¬ìš©ëœ í”¼ì²˜ë§Œìœ¼ë¡œ êµ¬ì„±
        X_for_plot = X[used_features_sanitized]

        # 3. í”Œë¡¯ì˜ ì¶•ì— í‘œì‹œí•  ì›ë³¸ í”¼ì²˜ ì´ë¦„ ëª©ë¡ ìƒì„±
        # sanitized ì´ë¦„ -> ì›ë³¸ ì´ë¦„ ë§¤í•‘ ìƒì„±
        name_map = dict(zip(new_columns, original_feature_names))
        feature_names_for_plot = [name_map.get(sanitized_name, sanitized_name) for sanitized_name in used_features_sanitized]
        
        # 4. summary_plotì— ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì™€ ì´ë¦„ì„ ì „ë‹¬
        shap.summary_plot(shap_values_to_plot, X_for_plot, feature_names=feature_names_for_plot, show=False)
        
        # --- ì—¬ê¸°ê¹Œì§€ ì¶”ê°€/ìˆ˜ì • ---
        plt.tight_layout()
        
        plot_func = _util_funcs.get('plot_to_dpg_texture')
        if plot_func:
            tex_tag, w, h, _ = plot_func(fig)
            plt.close(fig)
            _results_queue.put({"type": "shap_result", "tex_tag": tex_tag, "width": w, "height": h, "exp_id": experiment.id})

    except Exception as e:
        _results_queue.put({"type": "error", "log": f"SHAP Error: {e}"})
        traceback.print_exc()


# --- UI Creation ---
def create_ui(step_name: str, parent_container_tag: str, main_callbacks: dict):
    global _module_main_callbacks, _util_funcs
    _module_main_callbacks = main_callbacks
    _util_funcs = main_callbacks.get('get_util_funcs', lambda: {})()
    
    main_callbacks['register_step_group_tag'](step_name, TAG_S11_GROUP)

    with dpg.group(tag=TAG_S11_GROUP, parent=parent_container_tag, show=False):
        dpg.add_text(f"--- {step_name} ---")
        dpg.add_separator()
        
        with dpg.child_window(height=600, border=True, tag=TAG_S11_UPPER_VIZ_WINDOW):
            dpg.add_text("ML Modeling Dashboard", color=(255, 255, 0))
            dpg.add_separator()
            with dpg.tab_bar(tag=TAG_S11_VIZ_TAB_BAR):
                with dpg.tab(label="ğŸ§ª Experiments", tag=TAG_S11_EXPERIMENT_TAB):
                    _create_experiment_tracking_tab()
                # --- [1ë‹¨ê³„] AutoML íƒ­ UI ìƒì„± ---
                with dpg.tab(label="ğŸ¤– AutoML", tag=TAG_S11_AUTOML_TAB):
                    _create_automl_tab()

        with dpg.child_window(border=True):
             dpg.add_text("Training Progress & Log", color=(100, 200, 255))
             dpg.add_progress_bar(tag=TAG_S11_PROGRESS_BAR, default_value=0.0, width=-1)
             with dpg.child_window(height=-1, border=True, tag=TAG_S11_LOG_WINDOW):
                dpg.add_text("Ready for training...", tag="s11_log_text")
    
    main_callbacks['register_module_updater'](step_name, update_ui)

def _create_automl_tab():
    """(ìˆ˜ì •) AutoML íƒ­ì˜ UIë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    with dpg.group(horizontal=True):
        # AutoML ì œì–´íŒ
        with dpg.group(width=300, tag=TAG_S11_AUTOML_CONTROLS_GROUP):
            dpg.add_text("AutoML Settings", color=(255, 255, 0))
            dpg.add_separator()
            dpg.add_text("Data Source:")
            dpg.add_combo(label="", tag=TAG_S11_DF_SELECTOR, width=-1, callback=_on_df_selected_automl)
            dpg.add_text("Target Variable:")
            # Target ì½¤ë³´ë°•ìŠ¤ì— ì½œë°± ì¶”ê°€
            dpg.add_combo(label="", tag="s11_automl_target_combo", width=-1, callback=_on_automl_target_changed)
            
            # --- ì•„ë˜ Task Type ë¼ë””ì˜¤ ë²„íŠ¼ ì‚­ì œ ---
            # dpg.add_text("Task Type:")
            # dpg.add_radio_button(items=["binary", "reg"], tag="s11_automl_task_type", horizontal=True, default_value="binary")
            
            # --- ëŒ€ì‹  ì•„ë˜ í…ìŠ¤íŠ¸ ìœ„ì ¯ ì¶”ê°€ ---
            with dpg.group(horizontal=True):
                dpg.add_text("Detected Task Type:")
                dpg.add_text("(select target)", tag="s11_automl_detected_task", color=(255, 255, 0))

            dpg.add_text("Time Budget (seconds):")
            dpg.add_input_int(default_value=60, width=-1, tag="s11_automl_time_budget")
            dpg.add_separator()
            dpg.add_button(label="ğŸš€ Run AutoML", tag=TAG_S11_AUTOML_RUN_BUTTON, width=-1, height=40,
                           callback=_start_automl_run_callback)
        
        # AutoML ê²°ê³¼ í‘œì‹œ ì˜ì—­
        with dpg.child_window(border=True, tag=TAG_S11_AUTOML_RESULTS_GROUP):
            dpg.add_text("AutoML Results will be shown here.", tag="s11_automl_results_placeholder")

def _create_experiment_tracking_tab():
    """ê¸°ì¡´ ì‹¤í—˜ ì¶”ì  íƒ­ (UI ë™ì¼)"""
    with dpg.table(tag=TAG_S11_EXPERIMENT_TABLE, header_row=True, resizable=True, scrollY=True,
                   borders_innerH=True, borders_outerH=True, borders_innerV=True, borders_outerV=True):
        dpg.add_table_column(label="Timestamp")
        dpg.add_table_column(label="Model")
        dpg.add_table_column(label="Algorithm")
        dpg.add_table_column(label="Target")
        dpg.add_table_column(label="Actions")


# --- Callbacks ---
def _start_automl_run_callback():
    """(ìˆ˜ì •) Run AutoML ë²„íŠ¼ ì½œë°±"""
    df_name = dpg.get_value(TAG_S11_DF_SELECTOR)
    target = dpg.get_value("s11_automl_target_combo")
    # ë¼ë””ì˜¤ ë²„íŠ¼ ëŒ€ì‹  ë‚´ë¶€ ë³€ìˆ˜ì—ì„œ task_typeì„ ê°€ì ¸ì˜´
    task_type = _detected_task_type 
    time_budget = dpg.get_value("s11_automl_time_budget")
    
    if not df_name or not target:
        if _util_funcs: _util_funcs['_show_simple_modal_message']("Error", "Please select DataFrame and Target.")
        return
    
    # task_typeì´ ìœ íš¨í•œì§€ ê²€ì‚¬
    if not task_type:
        if _util_funcs: _util_funcs['_show_simple_modal_message']("Error", "Could not detect a valid task type.")
        return

    all_dfs = _module_main_callbacks['get_all_available_dfs']()
    df = all_dfs.get(df_name)

    if df is None:
        if _util_funcs: _util_funcs['_show_simple_modal_message']("Error", "DataFrame not found.")
        return
    
    _start_background_task(_run_automl_in_thread, args=(df.copy(), target, task_type, time_budget))

def _start_shap_analysis_callback(sender, app_data, user_data: ExperimentResult):
    """(ìˆ˜ì •) SHAP ë¶„ì„ ì‹œì‘ ë²„íŠ¼ ì½œë°±"""
    exp = user_data
    
    # ì‹¤í–‰ ì‹œì ì— main_appì—ì„œ ì§ì ‘ ëª¨ë“  DF ëª©ë¡ì„ ê°€ì ¸ì˜´
    all_dfs = _module_main_callbacks.get('get_all_available_dfs', lambda: {})()
    df = all_dfs.get(exp.dataframe_name)
    
    if df is None:
        _log_message(f"Error: DataFrame '{exp.dataframe_name}' for SHAP analysis not found.", "ERROR")
        return
    
    _start_background_task(_run_shap_in_thread, args=(exp, df.copy()))

def _on_df_selected_automl(sender, df_name, user_data):
    """AutoML íƒ­ì—ì„œ ë°ì´í„°í”„ë ˆì„ ì„ íƒ ì‹œ ì½œë°±"""
    _update_automl_target_combo(df_name)

# --- [1ë‹¨ê³„] ë¹„ë™ê¸° ê²°ê³¼ ì²˜ë¦¬ ë° UI ì—…ë°ì´íŠ¸ ---
def _check_for_updates():
    """ë§¤ í”„ë ˆì„ë§ˆë‹¤ íë¥¼ í™•ì¸í•˜ì—¬ UIë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜"""
    global _worker_thread
    try:
        # íì—ì„œ ë…¼ë¸”ë¡œí‚¹ìœ¼ë¡œ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
        result = _results_queue.get_nowait()
        
        if result["type"] == "progress":
            _update_progress(result["value"], result["log"])
        
        elif result["type"] == "error":
            _log_message(result["log"], "ERROR")
            _update_progress(0.0) # ì—ëŸ¬ ì‹œ í”„ë¡œê·¸ë ˆìŠ¤ ë°” ë¦¬ì…‹
        
        elif result["type"] == "automl_result":
            _display_automl_results(result["data"])
            _update_progress(1.0, "AutoML process finished.")
            time.sleep(1)
            _update_progress(0.0)

        elif result["type"] == "shap_result":
            _display_shap_results(result)
            _update_progress(1.0, "SHAP analysis finished.")
            time.sleep(1)
            _update_progress(0.0)

        _results_queue.task_done()

    except queue.Empty:
        # íê°€ ë¹„ì–´ìˆìœ¼ë©´ ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ
        pass
    except Exception as e:
        print(f"Error checking for updates: {e}")

    # ìŠ¤ë ˆë“œ ì¢…ë£Œ í™•ì¸
    if _worker_thread and not _worker_thread.is_alive():
        _worker_thread = None

# --- ê²°ê³¼ í‘œì‹œ í•¨ìˆ˜ ---
def _display_automl_results(data: dict):
    """AutoML ê²°ê³¼ë¥¼ UIì— í‘œì‹œ"""
    _log_message("Displaying AutoML results...")
    
    # ê²°ê³¼ ì €ì¥
    exp = ExperimentResult(
        id=str(uuid.uuid4()), timestamp=datetime.datetime.now(),
        model_name=data["model_name"], model_type=data["model_type"],
        algorithm=data["algorithm"], parameters={"time_budget": dpg.get_value("s11_automl_time_budget")},
        features=list(data["feature_scores"].keys()), target=data["target"],
        metrics={}, training_time=data["training_time"],
        model_object=data["model_object"], dataframe_name=dpg.get_value(TAG_S11_DF_SELECTOR)
    )
    _experiments_history.append(exp)
    _update_experiment_table()
    
    # AutoML ê²°ê³¼ íƒ­ ë¹„ìš°ê¸°
    res_group = TAG_S11_AUTOML_RESULTS_GROUP
    if dpg.does_item_exist(res_group):
        dpg.delete_item(res_group, children_only=True)
    
    # ê²°ê³¼ í‘œì‹œ
    dpg.add_text(f"Results for: {exp.model_name}", parent=res_group, color=(255, 255, 0))
    dpg.add_text(f"Training Time: {exp.training_time:.2f} seconds", parent=res_group)
    dpg.add_separator(parent=res_group)
    dpg.add_text("Feature Importances:", parent=res_group, color=(100, 200, 255))
    
    # í”¼ì²˜ ì¤‘ìš”ë„ í…Œì´ë¸”
    with dpg.table(header_row=True, parent=res_group):
        dpg.add_table_column(label="Feature")
        dpg.add_table_column(label="Importance")
        for feature, score in sorted(data["feature_scores"].items(), key=lambda x: x[1], reverse=True):
            with dpg.table_row():
                dpg.add_text(feature)
                dpg.add_text(f"{score:.4f}")

def _display_shap_results(data: dict):
    """SHAP ë¶„ì„ ê²°ê³¼ë¥¼ UIì— í‘œì‹œ"""
    exp_id = data['exp_id']
    result_tab_tag = f"s11_result_tab_{exp_id}"
    
    # í•´ë‹¹ ì‹¤í—˜ì˜ ê²°ê³¼ íƒ­ì´ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸
    if dpg.does_item_exist(result_tab_tag):
        # SHAP ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ í•´ë‹¹ íƒ­ì— ì¶”ê°€
        dpg.add_separator(parent=result_tab_tag)
        dpg.add_text("SHAP Summary Plot", parent=result_tab_tag, color=(100, 200, 255))
        dpg.add_image(data['tex_tag'], width=data['width'], height=data['height'], parent=result_tab_tag)
        _texture_tags.append(data['tex_tag']) # ë‚˜ì¤‘ì— ì‚­ì œí•˜ê¸° ìœ„í•´ íƒœê·¸ ì €ì¥
    else:
        _log_message(f"Info: Result tab for experiment {exp_id[:8]} is not open. SHAP plot not displayed.", "INFO")


def _create_results_visualizations(experiment: ExperimentResult):
    """ìˆ˜ë™ í•™ìŠµ ê²°ê³¼ íƒ­ ìƒì„± (SHAP ë²„íŠ¼ ì¶”ê°€)"""
    tab_name = f"ğŸ“ˆ {experiment.model_name}"
    tab_tag = f"s11_result_tab_{experiment.id}"
    
    if dpg.does_item_exist(tab_tag):
        dpg.focus_item(tab_tag)
        return

    with dpg.tab(label=tab_name, parent=TAG_S11_VIZ_TAB_BAR, closable=True, tag=tab_tag):
        dpg.add_text(f"Results for: {experiment.model_name}", color=(255, 255, 0))
        dpg.add_text(f"Algorithm: {experiment.algorithm}")
        dpg.add_separator()
        
        # --- [1ë‹¨ê³„] SHAP ë¶„ì„ ë²„íŠ¼ ì¶”ê°€ ---
        dpg.add_button(label="ğŸ”¬ Run SHAP Analysis", user_data=experiment, 
                       callback=_start_shap_analysis_callback)
        dpg.add_separator()
        
        # (ê¸°ì¡´ì˜ Confusion Matrix, ROC Curve ë“± ì‹œê°í™” ë¡œì§ì€ ì—¬ê¸°ì— ìœ„ì¹˜)

# --- Helper Functions (ê¸°ì¡´ í•¨ìˆ˜ë“¤ ì¼ë¶€ ìˆ˜ì • ë° ì¶”ê°€) ---
def _log_message(message: str, level: str = "INFO"):
    if not dpg.is_dearpygui_running(): return
    timestamp = datetime.datetime.now().strftime("%H:%M:%S")
    formatted_msg = f"[{timestamp}] {level}: {message}"
    if dpg.does_item_exist("s11_log_text"):
        current_log = dpg.get_value("s11_log_text")
        new_log = f"{current_log}\n{formatted_msg}"
        log_lines = new_log.split("\n")
        if len(log_lines) > 100: new_log = "\n".join(log_lines[-100:])
        dpg.set_value("s11_log_text", new_log)
        if dpg.does_item_exist(TAG_S11_LOG_WINDOW):
            dpg.set_y_scroll(TAG_S11_LOG_WINDOW, dpg.get_y_scroll_max(TAG_S11_LOG_WINDOW))

def _update_progress(value: float, message: str = ""):
    if not dpg.is_dearpygui_running(): return
    if dpg.does_item_exist(TAG_S11_PROGRESS_BAR):
        dpg.set_value(TAG_S11_PROGRESS_BAR, value)
    if message: _log_message(message)

def update_ui():
    """(ìˆ˜ì •) UI ì—…ë°ì´íŠ¸"""
    if not _module_main_callbacks: return
    
    # í•¨ìˆ˜ ë‚´ì—ì„œë§Œ ì‚¬ìš©í•  ì§€ì—­ ë³€ìˆ˜ë¡œ DF ëª©ë¡ì„ ê°€ì ¸ì˜´
    all_dfs = _module_main_callbacks.get('get_all_available_dfs', lambda: {})()
    
    df_selector_tag = TAG_S11_DF_SELECTOR
    if dpg.does_item_exist(df_selector_tag):
        df_names = list(all_dfs.keys())
        dpg.configure_item(df_selector_tag, items=df_names)
        
        current_selection = dpg.get_value(df_selector_tag)
        if not current_selection and df_names:
            current_selection = df_names[0]
            dpg.set_value(df_selector_tag, current_selection)

        if current_selection:
            _update_automl_target_combo(current_selection)

    _update_experiment_table()

def _update_experiment_table():
    """ì‹¤í—˜ ëª©ë¡ í…Œì´ë¸” ì—…ë°ì´íŠ¸"""
    if not dpg.does_item_exist(TAG_S11_EXPERIMENT_TABLE): return
    
    dpg.delete_item(TAG_S11_EXPERIMENT_TABLE, children_only=True)
    # í…Œì´ë¸” í—¤ë” ë‹¤ì‹œ ì¶”ê°€
    dpg.add_table_column(label="Timestamp", parent=TAG_S11_EXPERIMENT_TABLE)
    dpg.add_table_column(label="Model", parent=TAG_S11_EXPERIMENT_TABLE)
    dpg.add_table_column(label="Algorithm", parent=TAG_S11_EXPERIMENT_TABLE)
    dpg.add_table_column(label="Target", parent=TAG_S11_EXPERIMENT_TABLE)
    dpg.add_table_column(label="Actions", parent=TAG_S11_EXPERIMENT_TABLE)

    for exp in reversed(_experiments_history):
        with dpg.table_row(parent=TAG_S11_EXPERIMENT_TABLE):
            dpg.add_text(exp.timestamp.strftime("%H:%M:%S"))
            dpg.add_text(exp.model_name)
            dpg.add_text(exp.algorithm)
            dpg.add_text(exp.target)
            with dpg.group(horizontal=True):
                dpg.add_button(label="View", user_data=exp, callback=_view_experiment_details)

def _view_experiment_details(sender, app_data, user_data: ExperimentResult):
    """ì‹¤í—˜ ê²°ê³¼ ë³´ê¸° ì½œë°± (SHAP ë²„íŠ¼ì´ ìˆëŠ” íƒ­ì„ ìƒì„±)"""
    _create_results_visualizations(user_data)


def reset_state():
    """ìƒíƒœ ì´ˆê¸°í™”"""
    global _experiments_history, _texture_tags, _worker_thread
    if _worker_thread and _worker_thread.is_alive():
        # ì—¬ê¸°ì„œ ìŠ¤ë ˆë“œë¥¼ ê°•ì œ ì¢…ë£Œí•˜ëŠ” ê²ƒì€ ìœ„í—˜í•˜ë¯€ë¡œ, ì‚¬ìš©ìì—ê²Œ ì•Œë¦¬ëŠ” ê²ƒì´ ì¢‹ìŒ
        _log_message("Warning: A task is still running. Cannot reset state now.", "WARN")
        return

    _experiments_history.clear()
    for tag in _texture_tags:
        if dpg.does_item_exist(tag): dpg.delete_item(tag)
    _texture_tags.clear()
    
    if dpg.is_dearpygui_running():
        update_ui()
    _log_message("State has been reset.", "INFO")