# step_11_ml_modeling.py - 1ë‹¨ê³„ êµ¬í˜„ (ë¹„ë™ê¸° ì²˜ë¦¬, AutoML, SHAP)

"""
Step 11 ML Modeling & AI í†µí•© ëª¨ë“ˆ (Phase 1 Implementation)

ê°•í™”ëœ ê¸°ëŠ¥:
- ë¹„ë™ê¸° ì²˜ë¦¬:ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®å­¦ç¿’ãƒ»åˆ†æã«ã‚ˆã‚‹UIãƒ•ãƒªãƒ¼ã‚ºé˜²æ­¢
- AutoML: LightAutoMLì„ ì´ìš©í•œ ëª¨ë¸ ì„ íƒ, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ìë™í™”
- SHAP: ëª¨ë¸ ì˜ˆì¸¡ì— ëŒ€í•œ í”¼ì²˜ ì˜í–¥ë„ ë° ë°©í–¥ì„± ë¶„ì„
- ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§: í•™ìŠµ ê³¼ì • ë¡œê·¸ ë° ì§„í–‰ë¥  í‘œì‹œ
"""

import dearpygui.dearpygui as dpg
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
import traceback
import datetime
import pickle
import json
import sys
import uuid
from dataclasses import dataclass, asdict
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import (accuracy_score, precision_recall_fscore_support, confusion_matrix,
                           mean_squared_error, r2_score, mean_absolute_error, roc_curve, auc)
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import threading
import queue
import time

# --- ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„¤ì¹˜ í•„ìš”) ---
try:
    from lightautoml.automl.presets.tabular_presets import TabularAutoML
    from lightautoml.tasks import Task
except ImportError:
    TabularAutoML = None
    Task = None
try:
    import shap
except ImportError:
    shap = None

warnings.filterwarnings('ignore')

# --- Classification/Regression Models (ê¸°ì¡´ê³¼ ë™ì¼) ---
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
# ... (ê¸°íƒ€ ëª¨ë¸ë“¤ì€ ê°„ê²°ì„±ì„ ìœ„í•´ ìƒëµ)

# --- DPG Tags ---
TAG_S11_GROUP = "step11_ml_modeling_group"
TAG_S11_UPPER_VIZ_WINDOW = "step11_upper_viz_window"
TAG_S11_LOWER_CONTROL_PANEL = "step11_lower_control_panel"
TAG_S11_VIZ_TAB_BAR = "step11_viz_tab_bar"

TAG_S11_EXPERIMENT_TAB = "step11_experiment_tab"
TAG_S11_MONITORING_TAB = "step11_monitoring_tab"
# --- [1ë‹¨ê³„ ì¶”ê°€] ---
TAG_S11_AUTOML_TAB = "step11_automl_tab" 
TAG_S11_AUTOML_CONTROLS_GROUP = "s11_automl_controls_group"
TAG_S11_AUTOML_RESULTS_GROUP = "s11_automl_results_group"
TAG_S11_AUTOML_RUN_BUTTON = "s11_automl_run_button"

TAG_S11_PROGRESS_BAR = "step11_progress_bar"
TAG_S11_LOG_WINDOW = "step11_log_window"
TAG_S11_EXPERIMENT_TABLE = "step11_experiment_table"
TAG_S11_DF_SELECTOR = "step11_df_selector"

# --- ML_ALGORITHMS (ê¸°ì¡´ê³¼ ë™ì¼) ---
ML_ALGORITHMS = {
    "Classification": {
        "Logistic Regression": {"class": LogisticRegression, "params": {}},
        "Random Forest": {"class": RandomForestClassifier, "params": {"n_estimators": 100}},
    },
    "Regression": {
        "Linear Regression": {"class": LinearRegression, "params": {}},
        "Random Forest": {"class": RandomForestRegressor, "params": {"n_estimators": 100}},
    },
    "Clustering": {} # ê°„ê²°ì„± ìœ„í•´ ìƒëµ
}

# --- Module State ë³€ìˆ˜ ---
_module_main_callbacks: Optional[Dict] = None
_util_funcs: Optional[Dict[str, Any]] = None
_experiments_history: List['ExperimentResult'] = []
_texture_tags: List[str] = []
# --- [1ë‹¨ê³„ ì¶”ê°€] ë¹„ë™ê¸° ì²˜ë¦¬ ê´€ë ¨ ë³€ìˆ˜ ---
_results_queue = queue.Queue()
_worker_thread: Optional[threading.Thread] = None
_detected_task_type: str = "" 


@dataclass
class ExperimentResult:
    """ì‹¤í—˜ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤ (ê¸°ì¡´ê³¼ ë™ì¼)"""
    id: str
    timestamp: datetime.datetime
    model_name: str
    model_type: str
    algorithm: str
    parameters: Dict[str, Any]
    features: List[str]
    target: str
    metrics: Dict[str, Any]
    training_time: float
    model_object: Any # í•™ìŠµëœ ëª¨ë¸ ê°ì²´ ì €ì¥
    dataframe_name: str # ì–´ë–¤ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í•™ìŠµí–ˆëŠ”ì§€ ê¸°ë¡
    
    def to_dict(self):
        d = asdict(self)
        d.pop('model_object', None)
        return d
    
def _update_automl_target_combo(df_name: str):
    """(ìˆ˜ì •) AutoML íƒ­ì˜ íƒ€ê²Ÿ ë³€ìˆ˜ ëª©ë¡ì„ ì—…ë°ì´íŠ¸í•˜ê³ , ì „ì—­ íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •"""
    all_dfs = _module_main_callbacks['get_all_available_dfs']()
    if not df_name or df_name not in all_dfs:
        # DFê°€ ì—†ìœ¼ë©´ íƒ€ê²Ÿ ëª©ë¡ê³¼ íƒì§€ëœ Task ì´ˆê¸°í™”
        if dpg.does_item_exist("s11_automl_target_combo"): dpg.configure_item("s11_automl_target_combo", items=[])
        if dpg.does_item_exist("s11_automl_detected_task"): dpg.set_value("s11_automl_detected_task", "(select source)")
        return

    df = all_dfs[df_name]
    cols = df.columns.tolist()
    
    combo_tag = "s11_automl_target_combo"
    if not dpg.does_item_exist(combo_tag): return
        
    dpg.configure_item(combo_tag, items=cols)
    
    final_target = ""
    if _module_main_callbacks and 'get_selected_target_variable' in _module_main_callbacks:
        global_target = _module_main_callbacks['get_selected_target_variable']()
        if global_target and global_target in cols:
            final_target = global_target
        elif cols:
            final_target = cols[0]
            
    if final_target:
        dpg.set_value(combo_tag, final_target)
        # ê¸°ë³¸ê°’ ì„¤ì • í›„, Task íƒì§€ í•¨ìˆ˜ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í˜¸ì¶œ
        _detect_and_update_task_type(df_name, final_target)

def _detect_and_update_task_type(df_name: str, target_name: str):
    """(ì‹ ì„¤) ì„ íƒëœ Target ë³€ìˆ˜ë¥¼ ë¶„ì„í•˜ì—¬ Task ìœ í˜•ì„ ê²°ì •í•˜ê³  UIë¥¼ ì—…ë°ì´íŠ¸"""
    global _detected_task_type

    # ìµœì‹  DF ëª©ë¡ì„ ì§ì ‘ ê°€ì ¸ì˜´
    all_dfs = _module_main_callbacks['get_all_available_dfs']()
    if not df_name or not target_name or df_name not in all_dfs:
        _detected_task_type = ""
        if dpg.does_item_exist("s11_automl_detected_task"):
            dpg.set_value("s11_automl_detected_task", "(error)")
        return

    df = all_dfs[df_name]
    if target_name not in df.columns:
        _detected_task_type = ""
        return

    target_series = df[target_name]
    nunique = target_series.nunique()
    dtype_kind = target_series.dtype.kind
    
    task = 'reg'  # ê¸°ë³¸ê°’ì€ íšŒê·€(reg)
    
    # ë°ì´í„° íƒ€ì…ì´ ë¬¸ìì—´/ì¹´í…Œê³ ë¦¬ì´ê±°ë‚˜, ì •ìˆ˜í˜•ì¸ë° ê³ ìœ ê°’ì´ 20ê°œ ë¯¸ë§Œì¸ ê²½ìš°
    if dtype_kind in 'Ocb' or (dtype_kind == 'i' and nunique < 20):
        if nunique == 2:
            task = 'binary'
        else:
            task = 'multiclass'
    
    _detected_task_type = task
    if dpg.does_item_exist("s11_automl_detected_task"):
        dpg.set_value("s11_automl_detected_task", task)

def _on_automl_target_changed(sender, target_name, user_data):
    """(ì‹ ì„¤) AutoML íƒ€ê²Ÿ ì½¤ë³´ë°•ìŠ¤ ë³€ê²½ ì‹œ ì½œë°±"""
    df_name = dpg.get_value(TAG_S11_DF_SELECTOR)
    _detect_and_update_task_type(df_name, target_name)

# --- [1ë‹¨ê³„] ë¹„ë™ê¸° ì‘ì—… ë˜í¼ ---
def _start_background_task(target_func, args):
    """ì‘ì—… ìŠ¤ë ˆë“œë¥¼ ì‹œì‘í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    global _worker_thread
    if _worker_thread and _worker_thread.is_alive():
        _log_message("ERROR: A task is already running.", "ERROR")
        if _util_funcs: _util_funcs['_show_simple_modal_message']("Task Busy", "A previous task is still running. Please wait.")
        return
    _worker_thread = threading.Thread(target=target_func, args=args, daemon=True)
    _worker_thread.start()
    _update_progress(0.0, "Task started in background...")


# --- [1ë‹¨ê³„] AutoML í•µì‹¬ ë¡œì§ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰) ---
def _run_automl_in_thread(df: pd.DataFrame, target: str, task_type: str, time_budget: int):
    """LightAutoMLì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰"""
    start_time = time.time()
    try:
        if TabularAutoML is None:
            raise ImportError("LightAutoML is not installed. Please run 'pip install lightautoml'.")

        _results_queue.put({"type": "progress", "value": 0.1, "log": f"Starting AutoML for target '{target}'..."})
        
        task = Task(task_type)
        roles = {'target': target}
        
        automl = TabularAutoML(task=task, timeout=time_budget, cpu_limit=1,
                               general_params={"use_algos": [["lgb", "lgb_tuned", "cat", "cat_tuned"]]})

        _results_queue.put({"type": "progress", "value": 0.3, "log": "Fitting AutoML model..."})
        
        # LightAutoMLì€ ìì²´ì ìœ¼ë¡œ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•¨
        oof_predictions = automl.fit_predict(df, roles=roles, verbose=1)
        
        training_time = time.time() - start_time
        _results_queue.put({"type": "progress", "value": 0.9, "log": "AutoML fitting complete. Generating report..."})
        
        # ê²°ê³¼ ì •ë¦¬
        # ì‹¤ì œ ì˜ˆì¸¡ì€ automl.predict(test_data)ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
        # ì—¬ê¸°ì„œëŠ” í•™ìŠµ ë¦¬í¬íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ ê²°ê³¼ë¥¼ êµ¬ì„±
        report = {
            "model_name": f"AutoML_{target}",
            "algorithm": "LightAutoML",
            "model_type": "Classification" if task_type == 'binary' else "Regression",
            "target": target,
            "training_time": training_time,
            "feature_scores": automl.get_feature_scores().to_dict()['Importance'],
            "model_object": automl,
        }
        _results_queue.put({"type": "automl_result", "data": report})

    except Exception as e:
        _results_queue.put({"type": "error", "log": f"AutoML Error: {e}"})
        traceback.print_exc()


# --- [1ë‹¨ê³„] SHAP ë¶„ì„ ë¡œì§ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰) ---
def _run_shap_in_thread(experiment: ExperimentResult, df: pd.DataFrame):
    """SHAP ê³„ì‚°ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰"""
    try:
        if shap is None:
            raise ImportError("SHAP is not installed. Please run 'pip install shap'.")

        _results_queue.put({"type": "progress", "value": 0.1, "log": f"Starting SHAP analysis for '{experiment.model_name}'..."})
        
        model = experiment.model_object
        features = experiment.features
        X = df[features]
        
        # ë°ì´í„° ì „ì²˜ë¦¬ (Label Encoding ë“±)
        for col in X.select_dtypes(include=['object', 'category']).columns:
            le = LabelEncoder()
            X[col] = le.fit_transform(X[col].astype(str))

        _results_queue.put({"type": "progress", "value": 0.3, "log": "Creating SHAP explainer..."})
        explainer = shap.Explainer(model.predict, X)
        
        _results_queue.put({"type": "progress", "value": 0.6, "log": "Calculating SHAP values..."})
        shap_values = explainer(X)

        _results_queue.put({"type": "progress", "value": 0.9, "log": "Generating SHAP summary plot..."})
        
        # SHAP ìš”ì•½ í”Œë¡¯ ìƒì„±
        fig, ax = plt.subplots()
        shap.summary_plot(shap_values, X, show=False)
        plt.tight_layout()
        
        plot_func = _util_funcs.get('plot_to_dpg_texture')
        if plot_func:
            tex_tag, w, h, _ = plot_func(fig)
            plt.close(fig)
            _results_queue.put({"type": "shap_result", "tex_tag": tex_tag, "width": w, "height": h, "exp_id": experiment.id})

    except Exception as e:
        _results_queue.put({"type": "error", "log": f"SHAP Error: {e}"})
        traceback.print_exc()


# --- UI Creation ---
def create_ui(step_name: str, parent_container_tag: str, main_callbacks: dict):
    global _module_main_callbacks, _util_funcs
    _module_main_callbacks = main_callbacks
    _util_funcs = main_callbacks.get('get_util_funcs', lambda: {})()
    
    main_callbacks['register_step_group_tag'](step_name, TAG_S11_GROUP)

    with dpg.group(tag=TAG_S11_GROUP, parent=parent_container_tag, show=False):
        dpg.add_text(f"--- {step_name} ---")
        dpg.add_separator()
        
        with dpg.child_window(height=600, border=True, tag=TAG_S11_UPPER_VIZ_WINDOW):
            dpg.add_text("ML Modeling Dashboard", color=(255, 255, 0))
            dpg.add_separator()
            with dpg.tab_bar(tag=TAG_S11_VIZ_TAB_BAR):
                with dpg.tab(label="ğŸ§ª Experiments", tag=TAG_S11_EXPERIMENT_TAB):
                    _create_experiment_tracking_tab()
                # --- [1ë‹¨ê³„] AutoML íƒ­ UI ìƒì„± ---
                with dpg.tab(label="ğŸ¤– AutoML", tag=TAG_S11_AUTOML_TAB):
                    _create_automl_tab()

        with dpg.child_window(border=True):
             dpg.add_text("Training Progress & Log", color=(100, 200, 255))
             dpg.add_progress_bar(tag=TAG_S11_PROGRESS_BAR, default_value=0.0, width=-1)
             with dpg.child_window(height=-1, border=True, tag=TAG_S11_LOG_WINDOW):
                dpg.add_text("Ready for training...", tag="s11_log_text")
    
    main_callbacks['register_module_updater'](step_name, update_ui)

def _create_automl_tab():
    """(ìˆ˜ì •) AutoML íƒ­ì˜ UIë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    with dpg.group(horizontal=True):
        # AutoML ì œì–´íŒ
        with dpg.group(width=300, tag=TAG_S11_AUTOML_CONTROLS_GROUP):
            dpg.add_text("AutoML Settings", color=(255, 255, 0))
            dpg.add_separator()
            dpg.add_text("Data Source:")
            dpg.add_combo(label="", tag=TAG_S11_DF_SELECTOR, width=-1, callback=_on_df_selected_automl)
            dpg.add_text("Target Variable:")
            # Target ì½¤ë³´ë°•ìŠ¤ì— ì½œë°± ì¶”ê°€
            dpg.add_combo(label="", tag="s11_automl_target_combo", width=-1, callback=_on_automl_target_changed)
            
            # --- ì•„ë˜ Task Type ë¼ë””ì˜¤ ë²„íŠ¼ ì‚­ì œ ---
            # dpg.add_text("Task Type:")
            # dpg.add_radio_button(items=["binary", "reg"], tag="s11_automl_task_type", horizontal=True, default_value="binary")
            
            # --- ëŒ€ì‹  ì•„ë˜ í…ìŠ¤íŠ¸ ìœ„ì ¯ ì¶”ê°€ ---
            with dpg.group(horizontal=True):
                dpg.add_text("Detected Task Type:")
                dpg.add_text("(select target)", tag="s11_automl_detected_task", color=(255, 255, 0))

            dpg.add_text("Time Budget (seconds):")
            dpg.add_input_int(default_value=60, width=-1, tag="s11_automl_time_budget")
            dpg.add_separator()
            dpg.add_button(label="ğŸš€ Run AutoML", tag=TAG_S11_AUTOML_RUN_BUTTON, width=-1, height=40,
                           callback=_start_automl_run_callback)
        
        # AutoML ê²°ê³¼ í‘œì‹œ ì˜ì—­
        with dpg.child_window(border=True, tag=TAG_S11_AUTOML_RESULTS_GROUP):
            dpg.add_text("AutoML Results will be shown here.", tag="s11_automl_results_placeholder")

def _create_experiment_tracking_tab():
    """ê¸°ì¡´ ì‹¤í—˜ ì¶”ì  íƒ­ (UI ë™ì¼)"""
    with dpg.table(tag=TAG_S11_EXPERIMENT_TABLE, header_row=True, resizable=True, scrollY=True,
                   borders_innerH=True, borders_outerH=True, borders_innerV=True, borders_outerV=True):
        dpg.add_table_column(label="Timestamp")
        dpg.add_table_column(label="Model")
        dpg.add_table_column(label="Algorithm")
        dpg.add_table_column(label="Target")
        dpg.add_table_column(label="Actions")


# --- Callbacks ---
def _start_automl_run_callback():
    """(ìˆ˜ì •) Run AutoML ë²„íŠ¼ ì½œë°±"""
    df_name = dpg.get_value(TAG_S11_DF_SELECTOR)
    target = dpg.get_value("s11_automl_target_combo")
    # ë¼ë””ì˜¤ ë²„íŠ¼ ëŒ€ì‹  ë‚´ë¶€ ë³€ìˆ˜ì—ì„œ task_typeì„ ê°€ì ¸ì˜´
    task_type = _detected_task_type 
    time_budget = dpg.get_value("s11_automl_time_budget")
    
    if not df_name or not target:
        if _util_funcs: _util_funcs['_show_simple_modal_message']("Error", "Please select DataFrame and Target.")
        return
    
    # task_typeì´ ìœ íš¨í•œì§€ ê²€ì‚¬
    if not task_type:
        if _util_funcs: _util_funcs['_show_simple_modal_message']("Error", "Could not detect a valid task type.")
        return

    all_dfs = _module_main_callbacks['get_all_available_dfs']()
    df = all_dfs.get(df_name)

    if df is None:
        if _util_funcs: _util_funcs['_show_simple_modal_message']("Error", "DataFrame not found.")
        return
    
    _start_background_task(_run_automl_in_thread, args=(df.copy(), target, task_type, time_budget))

def _start_shap_analysis_callback(sender, app_data, user_data: ExperimentResult):
    """SHAP ë¶„ì„ ì‹œì‘ ë²„íŠ¼ ì½œë°±"""
    exp = user_data
    df = _available_dfs.get(exp.dataframe_name)
    if df is None:
        _log_message(f"Error: DataFrame '{exp.dataframe_name}' for SHAP analysis not found.", "ERROR")
        return
    
    # SHAP ë¶„ì„ì„ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹œì‘
    _start_background_task(_run_shap_in_thread, args=(exp, df.copy()))


def _on_df_selected_automl(sender, df_name, user_data):
    """AutoML íƒ­ì—ì„œ ë°ì´í„°í”„ë ˆì„ ì„ íƒ ì‹œ ì½œë°±"""
    _update_automl_target_combo(df_name)

# --- [1ë‹¨ê³„] ë¹„ë™ê¸° ê²°ê³¼ ì²˜ë¦¬ ë° UI ì—…ë°ì´íŠ¸ ---
def _check_for_updates():
    """ë§¤ í”„ë ˆì„ë§ˆë‹¤ íë¥¼ í™•ì¸í•˜ì—¬ UIë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜"""
    global _worker_thread
    try:
        # íì—ì„œ ë…¼ë¸”ë¡œí‚¹ìœ¼ë¡œ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
        result = _results_queue.get_nowait()
        
        if result["type"] == "progress":
            _update_progress(result["value"], result["log"])
        
        elif result["type"] == "error":
            _log_message(result["log"], "ERROR")
            _update_progress(0.0) # ì—ëŸ¬ ì‹œ í”„ë¡œê·¸ë ˆìŠ¤ ë°” ë¦¬ì…‹
        
        elif result["type"] == "automl_result":
            _display_automl_results(result["data"])
            _update_progress(1.0, "AutoML process finished.")
            time.sleep(1)
            _update_progress(0.0)

        elif result["type"] == "shap_result":
            _display_shap_results(result)
            _update_progress(1.0, "SHAP analysis finished.")
            time.sleep(1)
            _update_progress(0.0)

        _results_queue.task_done()

    except queue.Empty:
        # íê°€ ë¹„ì–´ìˆìœ¼ë©´ ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ
        pass
    except Exception as e:
        print(f"Error checking for updates: {e}")

    # ìŠ¤ë ˆë“œ ì¢…ë£Œ í™•ì¸
    if _worker_thread and not _worker_thread.is_alive():
        _worker_thread = None

# --- ê²°ê³¼ í‘œì‹œ í•¨ìˆ˜ ---
def _display_automl_results(data: dict):
    """AutoML ê²°ê³¼ë¥¼ UIì— í‘œì‹œ"""
    _log_message("Displaying AutoML results...")
    
    # ê²°ê³¼ ì €ì¥
    exp = ExperimentResult(
        id=str(uuid.uuid4()), timestamp=datetime.datetime.now(),
        model_name=data["model_name"], model_type=data["model_type"],
        algorithm=data["algorithm"], parameters={"time_budget": dpg.get_value("s11_automl_time_budget")},
        features=list(data["feature_scores"].keys()), target=data["target"],
        metrics={}, training_time=data["training_time"],
        model_object=data["model_object"], dataframe_name=dpg.get_value(TAG_S11_DF_SELECTOR)
    )
    _experiments_history.append(exp)
    _update_experiment_table()
    
    # AutoML ê²°ê³¼ íƒ­ ë¹„ìš°ê¸°
    res_group = TAG_S11_AUTOML_RESULTS_GROUP
    if dpg.does_item_exist(res_group):
        dpg.delete_item(res_group, children_only=True)
    
    # ê²°ê³¼ í‘œì‹œ
    dpg.add_text(f"Results for: {exp.model_name}", parent=res_group, color=(255, 255, 0))
    dpg.add_text(f"Training Time: {exp.training_time:.2f} seconds", parent=res_group)
    dpg.add_separator(parent=res_group)
    dpg.add_text("Feature Importances:", parent=res_group, color=(100, 200, 255))
    
    # í”¼ì²˜ ì¤‘ìš”ë„ í…Œì´ë¸”
    with dpg.table(header_row=True, parent=res_group):
        dpg.add_table_column(label="Feature")
        dpg.add_table_column(label="Importance")
        for feature, score in sorted(data["feature_scores"].items(), key=lambda x: x[1], reverse=True):
            with dpg.table_row():
                dpg.add_text(feature)
                dpg.add_text(f"{score:.4f}")

def _display_shap_results(data: dict):
    """SHAP ë¶„ì„ ê²°ê³¼ë¥¼ UIì— í‘œì‹œ"""
    exp_id = data['exp_id']
    result_tab_tag = f"s11_result_tab_{exp_id}"
    
    # í•´ë‹¹ ì‹¤í—˜ì˜ ê²°ê³¼ íƒ­ì´ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸
    if dpg.does_item_exist(result_tab_tag):
        # SHAP ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ í•´ë‹¹ íƒ­ì— ì¶”ê°€
        dpg.add_separator(parent=result_tab_tag)
        dpg.add_text("SHAP Summary Plot", parent=result_tab_tag, color=(100, 200, 255))
        dpg.add_image(data['tex_tag'], width=data['width'], height=data['height'], parent=result_tab_tag)
        _texture_tags.append(data['tex_tag']) # ë‚˜ì¤‘ì— ì‚­ì œí•˜ê¸° ìœ„í•´ íƒœê·¸ ì €ì¥
    else:
        _log_message(f"Info: Result tab for experiment {exp_id[:8]} is not open. SHAP plot not displayed.", "INFO")


def _create_results_visualizations(experiment: ExperimentResult):
    """ìˆ˜ë™ í•™ìŠµ ê²°ê³¼ íƒ­ ìƒì„± (SHAP ë²„íŠ¼ ì¶”ê°€)"""
    tab_name = f"ğŸ“ˆ {experiment.model_name}"
    tab_tag = f"s11_result_tab_{experiment.id}"
    
    if dpg.does_item_exist(tab_tag):
        dpg.focus_item(tab_tag)
        return

    with dpg.tab(label=tab_name, parent=TAG_S11_VIZ_TAB_BAR, closable=True, tag=tab_tag):
        dpg.add_text(f"Results for: {experiment.model_name}", color=(255, 255, 0))
        dpg.add_text(f"Algorithm: {experiment.algorithm}")
        dpg.add_separator()
        
        # --- [1ë‹¨ê³„] SHAP ë¶„ì„ ë²„íŠ¼ ì¶”ê°€ ---
        dpg.add_button(label="ğŸ”¬ Run SHAP Analysis", user_data=experiment, 
                       callback=_start_shap_analysis_callback)
        dpg.add_separator()
        
        # (ê¸°ì¡´ì˜ Confusion Matrix, ROC Curve ë“± ì‹œê°í™” ë¡œì§ì€ ì—¬ê¸°ì— ìœ„ì¹˜)

# --- Helper Functions (ê¸°ì¡´ í•¨ìˆ˜ë“¤ ì¼ë¶€ ìˆ˜ì • ë° ì¶”ê°€) ---
def _log_message(message: str, level: str = "INFO"):
    if not dpg.is_dearpygui_running(): return
    timestamp = datetime.datetime.now().strftime("%H:%M:%S")
    formatted_msg = f"[{timestamp}] {level}: {message}"
    if dpg.does_item_exist("s11_log_text"):
        current_log = dpg.get_value("s11_log_text")
        new_log = f"{current_log}\n{formatted_msg}"
        log_lines = new_log.split("\n")
        if len(log_lines) > 100: new_log = "\n".join(log_lines[-100:])
        dpg.set_value("s11_log_text", new_log)
        if dpg.does_item_exist(TAG_S11_LOG_WINDOW):
            dpg.set_y_scroll(TAG_S11_LOG_WINDOW, dpg.get_y_scroll_max(TAG_S11_LOG_WINDOW))

def _update_progress(value: float, message: str = ""):
    if not dpg.is_dearpygui_running(): return
    if dpg.does_item_exist(TAG_S11_PROGRESS_BAR):
        dpg.set_value(TAG_S11_PROGRESS_BAR, value)
    if message: _log_message(message)

def update_ui():
    """(ìˆ˜ì •) UI ì—…ë°ì´íŠ¸"""
    if not _module_main_callbacks: return
    
    # í•¨ìˆ˜ ë‚´ì—ì„œë§Œ ì‚¬ìš©í•  ì§€ì—­ ë³€ìˆ˜ë¡œ DF ëª©ë¡ì„ ê°€ì ¸ì˜´
    all_dfs = _module_main_callbacks.get('get_all_available_dfs', lambda: {})()
    
    df_selector_tag = TAG_S11_DF_SELECTOR
    if dpg.does_item_exist(df_selector_tag):
        df_names = list(all_dfs.keys())
        dpg.configure_item(df_selector_tag, items=df_names)
        
        current_selection = dpg.get_value(df_selector_tag)
        if not current_selection and df_names:
            current_selection = df_names[0]
            dpg.set_value(df_selector_tag, current_selection)

        if current_selection:
            _update_automl_target_combo(current_selection)

    _update_experiment_table()

def _update_experiment_table():
    """ì‹¤í—˜ ëª©ë¡ í…Œì´ë¸” ì—…ë°ì´íŠ¸"""
    if not dpg.does_item_exist(TAG_S11_EXPERIMENT_TABLE): return
    
    dpg.delete_item(TAG_S11_EXPERIMENT_TABLE, children_only=True)
    # í…Œì´ë¸” í—¤ë” ë‹¤ì‹œ ì¶”ê°€
    dpg.add_table_column(label="Timestamp", parent=TAG_S11_EXPERIMENT_TABLE)
    dpg.add_table_column(label="Model", parent=TAG_S11_EXPERIMENT_TABLE)
    dpg.add_table_column(label="Algorithm", parent=TAG_S11_EXPERIMENT_TABLE)
    dpg.add_table_column(label="Target", parent=TAG_S11_EXPERIMENT_TABLE)
    dpg.add_table_column(label="Actions", parent=TAG_S11_EXPERIMENT_TABLE)

    for exp in reversed(_experiments_history):
        with dpg.table_row(parent=TAG_S11_EXPERIMENT_TABLE):
            dpg.add_text(exp.timestamp.strftime("%H:%M:%S"))
            dpg.add_text(exp.model_name)
            dpg.add_text(exp.algorithm)
            dpg.add_text(exp.target)
            with dpg.group(horizontal=True):
                dpg.add_button(label="View", user_data=exp, callback=_view_experiment_details)

def _view_experiment_details(sender, app_data, user_data: ExperimentResult):
    """ì‹¤í—˜ ê²°ê³¼ ë³´ê¸° ì½œë°± (SHAP ë²„íŠ¼ì´ ìˆëŠ” íƒ­ì„ ìƒì„±)"""
    _create_results_visualizations(user_data)


def reset_state():
    """ìƒíƒœ ì´ˆê¸°í™”"""
    global _experiments_history, _texture_tags, _worker_thread
    if _worker_thread and _worker_thread.is_alive():
        # ì—¬ê¸°ì„œ ìŠ¤ë ˆë“œë¥¼ ê°•ì œ ì¢…ë£Œí•˜ëŠ” ê²ƒì€ ìœ„í—˜í•˜ë¯€ë¡œ, ì‚¬ìš©ìì—ê²Œ ì•Œë¦¬ëŠ” ê²ƒì´ ì¢‹ìŒ
        _log_message("Warning: A task is still running. Cannot reset state now.", "WARN")
        return

    _experiments_history.clear()
    for tag in _texture_tags:
        if dpg.does_item_exist(tag): dpg.delete_item(tag)
    _texture_tags.clear()
    
    if dpg.is_dearpygui_running():
        update_ui()
    _log_message("State has been reset.", "INFO")